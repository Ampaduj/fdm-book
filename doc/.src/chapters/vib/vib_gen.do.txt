======= Generalization: damping, nonlinearities, and excitation =======
label{vib:model2}

idx{nonlinear restoring force}
idx{nonlinear spring}
idx{forced vibrations}

We shall now generalize the simple model problem from
Section ref{vib:model1} to include a possibly nonlinear damping term $f(u^{\prime})$,
a possibly nonlinear spring (or restoring) force $s(u)$, and
some external excitation $F(t)$:

!bt
\begin{equation}
mu^{\prime\prime} + f(u^{\prime}) + s(u) = F(t),\quad u(0)=I,\ u^{\prime}(0)=V,\ t\in (0,T]
\tp
label{vib:ode2}
\end{equation}
!et
We have also included a possibly nonzero initial value of $u^{\prime}(0)$.
The parameters $m$, $f(u^{\prime})$, $s(u)$, $F(t)$, $I$, $V$, and $T$ are
input data.

There are two main types of damping (friction) forces: linear $f(u^{\prime})=bu$, or
quadratic $f(u^{\prime})=bu^{\prime}|u^{\prime}|$. Spring systems often feature linear
damping, while air resistance usually gives rise to quadratic damping.
Spring forces are often linear: $s(u)=cu$, but nonlinear versions
are also common, the most famous is the gravity force on a pendulum
that acts as a spring with $s(u)\sim \sin(u)$.


===== A centered scheme for linear damping =====
label{vib:ode2:fdm:flin}

Sampling (ref{vib:ode2}) at a mesh point $t_n$, replacing
$u^{\prime\prime}(t_n)$ by $[D_tD_tu]^n$, and $u^{\prime}(t_n)$ by $[D_{2t}u]^n$ results
in the discretization

!bt
\begin{equation}
[mD_tD_t u + f(D_{2t}u) + s(u) = F]^n,
\end{equation}
!et
which written out means

!bt
\begin{equation}
m\frac{u^{n+1}-2u^n + u^{n-1}}{\Delta t^2}
+ f(\frac{u^{n+1}-u^{n-1}}{2\Delta t}) + s(u^n) = F^n,
label{vib:ode2:step3b}
\end{equation}
!et
where $F^n$ as usual means $F(t)$ evaluated at $t=t_n$.
Solving (ref{vib:ode2:step3b}) with respect to the unknown
$u^{n+1}$ gives a problem: the $u^{n+1}$ inside the $f$ function
makes the equation *nonlinear* unless $f(u^{\prime})$ is a linear function,
$f(u^{\prime})=bu^{\prime}$. For now we shall assume that $f$ is linear in $u^{\prime}$.
Then

!bt
\begin{equation}
m\frac{u^{n+1}-2u^n + u^{n-1}}{\Delta t^2}
+ b\frac{u^{n+1}-u^{n-1}}{2\Delta t} + s(u^n) = F^n,
label{vib:ode2:step3b2}
\end{equation}
!et
which gives an explicit formula for $u$ at each
new time level:

!bt
\begin{equation}
u^{n+1} = (2mu^n + (\frac{b}{2}\Delta t - m)u^{n-1} +
\Delta t^2(F^n - s(u^n)))(m + \frac{b}{2}\Delta t)^{-1}
label{vib:ode2:step4}
\tp
\end{equation}
!et

For the first time step we need to discretize $u^{\prime}(0)=V$
as $[D_{2t}u = V]^0$ and combine
with (ref{vib:ode2:step4}) for $n=0$. The discretized initial condition
leads to

!bt
\begin{equation}
u^{-1} = u^{1} - 2\Delta t V,
label{vib:ode2:ic:du}
\end{equation}
!et
which inserted in (ref{vib:ode2:step4}) for $n=0$ gives an equation
that can be solved for
$u^1$:

!bt
\begin{equation}
u^1 = u^0 + \Delta t\, V
+ \frac{\Delta t^2}{2m}(-bV - s(u^0) + F^0)
\tp
label{vib:ode2:step4b}
\end{equation}
!et

===== A centered scheme for quadratic damping =====
label{vib:ode2:fdm:fquad}

When $f(u^{\prime})=bu^{\prime}|u^{\prime}|$, we get a quadratic equation for $u^{n+1}$
in (ref{vib:ode2:step3b}). This equation can be straightforwardly
solved by the well-known formula for the roots of a quadratic equation.
However, we can also avoid the nonlinearity by introducing
an approximation with an error of order no higher than what we
already have from replacing derivatives with finite differences.

idx{geometric mean}
idx{averaging!geometric}

We start with (ref{vib:ode2}) and only replace
$u^{\prime\prime}$ by $D_tD_tu$, resulting in

!bt
\begin{equation}
[mD_tD_t u + bu^{\prime}|u^{\prime}| + s(u) = F]^n\tp
label{vib:ode2:quad:idea1}
\end{equation}
!et
Here, $u^{\prime}|u^{\prime}|$ is to be computed at time $t_n$. The idea
is now to introduce
a *geometric mean*, defined by

!bt
\[ (w^2)^n \approx w^{n-\half}w^{n+\half},\]
!et
for some quantity $w$ depending on time. The error in the geometric mean
approximation is $\Oof{\Delta t^2}$, the same as in the
approximation $u^{\prime\prime}\approx D_tD_tu$. With $w=u^{\prime}$ it follows
that

!bt
\[ [u^{\prime}|u^{\prime}|]^n \approx u^{\prime}(t_{n+\half})|u^{\prime}(t_{n-\half})|\tp\]
!et
The next step is to approximate
$u^{\prime}$ at $t_{n\pm 1/2}$, and fortunately a centered difference
fits perfectly into the formulas since it involves $u$ values at
the mesh points only. With the approximations


!bt
\begin{equation}
u^{\prime}(t_{n+1/2})\approx [D_t u]^{n+\half},\quad u^{\prime}(t_{n-1/2})\approx [D_t u]^{n-\half},
label{vib:ode2:quad:idea2}
\end{equation}
!et
we get

!bt
\begin{equation}
[u^{\prime}|u^{\prime}|]^n
\approx [D_tu]^{n+\half}|[D_tu]^{n-\half}| = \frac{u^{n+1}-u^n}{\Delta t}
\frac{|u^n-u^{n-1}|}{\Delta t}
\tp
\end{equation}
!et
The counterpart to (ref{vib:ode2:step3b}) is then

!bt
\begin{equation}
m\frac{u^{n+1}-2u^n + u^{n-1}}{\Delta t^2}
+ b\frac{u^{n+1}-u^n}{\Delta t}\frac{|u^n-u^{n-1}|}{\Delta t}
+ s(u^n) = F^n,
label{vib:ode2:step3b:quad}
\end{equation}
!et
which is linear in the unknown $u^{n+1}$. Therefore, we can easily solve
(ref{vib:ode2:step3b:quad})
with respect to $u^{n+1}$ and achieve the explicit updating formula

!bt
\begin{align}
u^{n+1} &=  \left( m + b|u^n-u^{n-1}|\right)^{-1}\times \nonumber\\
& \qquad \left(2m u^n - mu^{n-1} + bu^n|u^n-u^{n-1}| + \Delta t^2 (F^n - s(u^n))
\right)
\tp
label{vib:ode2:step4:quad}
\end{align}
!et

# Make exercise to solve complicated u^1 equation with Bisection/Newton

In the derivation of a special equation for the first
time step we run into some trouble: inserting (ref{vib:ode2:ic:du})
in (ref{vib:ode2:step4:quad}) for $n=0$ results in a complicated nonlinear
equation for $u^1$. By thinking differently about the problem we can
easily get away with the nonlinearity again. We have for $n=0$ that
$b[u^{\prime}|u^{\prime}|]^0 = bV|V|$. Using this value in (ref{vib:ode2:quad:idea1})
gives

!bt
\begin{equation}
[mD_tD_t u + bV|V| + s(u) = F]^0
\tp
\end{equation}
!et
Writing this equation out and using (ref{vib:ode2:ic:du}) results in the
special equation for the first time step:

!bt
\begin{equation}
u^1 = u^0 + \Delta t V + \frac{\Delta t^2}{2m}\left(-bV|V| - s(u^0) + F^0\right)
\tp
label{vib:ode2:step4b:quad}
\end{equation}
!et

===== A forward-backward discretization of the quadratic damping term =====

The previous section first proposed to discretize the quadratic
damping term $|u^{\prime}|u^{\prime}$ using centered differences:
$[|D_{2t}|D_{2t}u]^n$. As this gives rise to a nonlinearity in
$u^{n+1}$, it was instead proposed to use a geometric mean combined
with centered differences.  But there are other alternatives. To get
rid of the nonlinearity in $[|D_{2t}|D_{2t}u]^n$, one can think
differently: apply a backward difference to $|u^{\prime}|$, such that
the term involves known values, and apply a forward difference to
$u^{\prime}$ to make the term linear in the unknown $u^{n+1}$. With
mathematics,

!bt
\begin{equation}
[\beta |u^{\prime}|u^{\prime}]^n \approx \beta |[D_t^-u]^n|[D_t^+ u]^n =
\beta\left\vert\frac{u^n-u^{n-1}}{\Delta t}\right\vert
\frac{u^{n+1}-u^n}{\Delta t}\tp
label{vib:ode2:nonlin:fbdiff}
\end{equation}
!et
The forward and backward differences have both an error proportional
to $\Delta t$ so one may think the discretization above leads to
a first-order scheme.
However, by looking at the formulas, we realize that the forward-backward
differences in (ref{vib:ode2:nonlin:fbdiff})
result in exactly the same scheme as in
(ref{vib:ode2:step3b:quad}) where we
used a geometric mean and centered differences and committed errors
of size $\Oof{\Delta t^2}$. Therefore, the forward-backward
differences in (ref{vib:ode2:nonlin:fbdiff})
act in a symmetric way and actually produce a second-order
accurate discretization of the quadratic damping term.


===== Implementation =====
label{vib:ode2:solver}

The algorithm arising from the methods in Sections ref{vib:ode2:fdm:flin}
and ref{vib:ode2:fdm:fquad} is very similar to the undamped case in
Section ref{vib:ode1:fdm}. The difference is
basically a question of different formulas for $u^1$ and
$u^{n+1}$. This is actually quite remarkable. The equation
(ref{vib:ode2}) is normally impossible to solve by pen and paper, but
possible for some special choices of $F$, $s$, and $f$. On the
contrary, the complexity of the
nonlinear generalized model (ref{vib:ode2}) versus the
simple undamped model is not a big deal when we solve the
problem numerically!

The computational algorithm takes the form

  o $u^0=I$
  o compute $u^1$ from (ref{vib:ode2:step4b}) if linear
    damping or (ref{vib:ode2:step4b:quad}) if quadratic damping
  o for $n=1,2,\ldots,N_t-1$:
    o compute $u^{n+1}$ from (ref{vib:ode2:step4}) if linear
      damping or (ref{vib:ode2:step4:quad}) if quadratic damping

Modifying the `solver` function for the undamped case is fairly
easy, the big difference being many more terms and if tests on
the type of damping:

@@@CODE src-vib/vib.py fromto: def solver@def visualize
The complete code resides in the file "`vib.py`": "${src_vib}/vib.py".

===== Verification =====
label{vib:ode2:verify}

=== Constant solution ===

For debugging and initial verification, a constant solution is often
very useful. We choose $\uex(t)=I$, which implies $V=0$.
Inserted in the ODE, we get
$F(t)=s(I)$ for any choice of $f$. Since the discrete derivative
of a constant vanishes (in particular, $[D_{2t}I]^n=0$,
$[D_tI]^n=0$, and $[D_tD_t I]^n=0$), the constant solution also fulfills
the discrete equations. The constant should therefore be reproduced
to machine precision. The function `test_constant` in `vib.py`
implements this test.

=== Linear solution ===

Now we choose a linear solution: $\uex = ct + d$. The initial condition
$u(0)=I$ implies $d=I$, and $u^{\prime}(0)=V$ forces $c$ to be $V$.
Inserting $\uex=Vt+I$ in the ODE with linear damping results in

!bt
\[ 0 + bV + s(Vt+I) = F(t),\]
!et
while quadratic damping requires the source term

!bt
\[ 0 + b|V|V + s(Vt+I) = F(t)\tp\]
!et
Since the finite difference approximations used to compute $u^{\prime}$ all
are exact for a linear function, it turns out that the linear $\uex$
is also a solution of the discrete equations.
Exercise ref{vib:exer:verify:gen:linear} asks you to carry out
all the details.

=== Quadratic solution ===

Choosing $\uex = bt^2 + Vt + I$, with $b$ arbitrary,
fulfills the initial conditions and
fits the ODE if $F$ is adjusted properly. The solution also solves
the discrete equations with linear damping. However, this quadratic
polynomial in $t$ does not fulfill the discrete equations in case
of quadratic damping, because the geometric mean used in the approximation
of this term introduces an error.
Doing Exercise ref{vib:exer:verify:gen:linear} will reveal
the details. One can fit $F^n$ in the discrete equations such that
the quadratic polynomial is reproduced by the numerical method (to
machine precision).

=== Catching bugs ===

How good are the constant and quadratic solutions at catching
bugs in the implementation?

 * Use `m` instead of `2*m` in the denominator of `u[1]`: constant
   works, while quadratic fails.
 * Use `b*dt` instead of `b*dt/2` in the updating formula for `u[n+1]`
   in case of linear damping: constant and quadratic fail.
 * Use `F[n+1]` instead of `F[n]` in case of linear or quadratic damping:
   constant solution works, quadratic fails.

We realize that the constant solution is very useful to catch bugs because
of its simplicity (easy to predict what the different terms in the
formula should evaluate to), while it seems the quadratic solution is
capable of detecting all other types of typos in the scheme (?).
This results demonstrates why we focus so much on exact, simple polynomial
solutions of the numerical schemes in these writings.

# More: classes, cases with pendulum approx u vs sin(u),
# making UI via parampool

===== Visualization =====
label{vib:ode2:viz}

The functions for visualizations differ significantly from
those in the undamped case in the `vib_undamped.py` program because,
in the present general case, we do not have an exact solution to
include in the plots. Moreover, we have no good estimate of
the periods of the oscillations as there will be one period
determined by the system parameters, essentially the
approximate frequency $\sqrt{s'(0)/m}$ for linear $s$ and small damping,
and one period dictated by $F(t)$ in case the excitation is periodic.
This is, however,
nothing that the program can depend on or make use of.
Therefore, the user has to specify $T$ and the window width
to get a plot that moves with the graph and shows
the most recent parts of it in long time simulations.

The `vib.py` code
contains several functions for analyzing the time series signal
and for visualizing the solutions.

===== User interface =====
label{vib:ode2:ui}

idx{`ArgumentParser` (Python class)}
idx{`argparse` (Python module)}

The `main` function is changed substantially from
the `vib_undamped.py` code, since we need to
specify the new data $c$, $s(u)$, and $F(t)$.  In addition, we must
set $T$ and the plot window width (instead of the number of periods we
want to simulate as in `vib_undamped.py`). To figure out whether we
can use one plot for the whole time series or if we should follow the
most recent part of $u$, we can use the `plot_empricial_freq_and_amplitude`
function's estimate of the number of local maxima. This number is now
returned from the function and used in `main` to decide on the
visualization technique.

!bc pycod
def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--I', type=float, default=1.0)
    parser.add_argument('--V', type=float, default=0.0)
    parser.add_argument('--m', type=float, default=1.0)
    parser.add_argument('--c', type=float, default=0.0)
    parser.add_argument('--s', type=str, default='u')
    parser.add_argument('--F', type=str, default='0')
    parser.add_argument('--dt', type=float, default=0.05)
    parser.add_argument('--T', type=float, default=140)
    parser.add_argument('--damping', type=str, default='linear')
    parser.add_argument('--window_width', type=float, default=30)
    parser.add_argument('--savefig', action='store_true')
    a = parser.parse_args()
    from scitools.std import StringFunction
    s = StringFunction(a.s, independent_variable='u')
    F = StringFunction(a.F, independent_variable='t')
    I, V, m, c, dt, T, window_width, savefig, damping = \
       a.I, a.V, a.m, a.c, a.dt, a.T, a.window_width, a.savefig, \
       a.damping

    u, t = solver(I, V, m, c, s, F, dt, T)
    num_periods = empirical_freq_and_amplitude(u, t)
    if num_periods <= 15:
        figure()
        visualize(u, t)
    else:
        visualize_front(u, t, window_width, savefig)
    show()
!ec
The program `vib.py` contains
the above code snippets and can solve the model problem
(ref{vib:ode2}). As a demo of `vib.py`, we consider the case
$I=1$, $V=0$, $m=1$, $c=0.03$, $s(u)=\sin(u)$, $F(t)=3\cos(4t)$,
$\Delta t = 0.05$, and $T=140$. The relevant command to run is

!bc sys
Terminal> python vib.py --s 'sin(u)' --F '3*cos(4*t)' --c 0.03
!ec
This results in a "moving window following the function":
"${doc_notes}/mov-vib/vib_generalized_dt0.05/index.html" on the screen.
Figure ref{vib:ode2:fig:demo} shows a part of the time series.

FIGURE: [fig-vib/vib_gen_demo, width=600 frac=1.0] Damped oscillator excited by a sinusoidal function. label{vib:ode2:fig:demo}

===== The Euler-Cromer scheme for the generalized model =====
label{vib:ode2:EulerCromer}

The ideas of the Euler-Cromer method from Section ref{vib:model2x2:EulerCromer}
carry over to the generalized model. We write (ref{vib:ode2})
as two equations for $u$ and $v=u^{\prime}$. The first equation is taken as the
one with $v^{\prime}$ on the left-hand side:

!bt
\begin{align}
v^{\prime} &= \frac{1}{m}(F(t)-s(u)-f(v)),
label{vib:ode2:EulerCromer:veq}\\
u^{\prime} &= v\tp
label{vib:ode2:EulerCromer:ueq}
\end{align}
!et
The idea is to step (ref{vib:ode2:EulerCromer:veq}) forward using
a standard Forward Euler method, while we update $u$ from
(ref{vib:ode2:EulerCromer:ueq}) with a Backward Euler method,
utilizing the recent, computed $v^{n+1}$ value. In detail,

!bt
\begin{align}
\frac{v^{n+1}-v^n}{\Delta t} &= \frac{1}{m}(F(t_n)-s(u^n)-f(v^n)),
label{vib:ode2:EulerCromer:dveq0a}\\
\frac{u^{n+1}-u^n}{\Delta t} &= v^{n+1},
label{vib:ode2:EulerCromer:dueq0a}
\end{align}
!et
resulting in the explicit scheme

!bt
\begin{align}
v^{n+1} &= v^n + \Delta t\frac{1}{m}(F(t_n)-s(u^n)-f(v^n)),
label{vib:ode2:EulerCromer:dveq}\\
u^{n+1} &= u^n + \Delta t\,v^{n+1}\tp
label{vib:ode2:EulerCromer:dueq0}
\end{align}
!et
We immediately note one very favorable feature of this scheme: all the
nonlinearities in $s(u)$ and $f(v)$ are evaluated at a previous time
level. This makes the Euler-Cromer method easier to apply and
hence much more convenient than the centered scheme for the second-order
ODE (ref{vib:ode2}).

The initial conditions are trivially set as

!bt
\begin{align}
v^0 &= V,\\
u^0 &= I\tp
\end{align}
!et

[hpl: odespy for the generalized problem]

# Discussion of which method is best:
# http://gamedev.stackexchange.com/questions/33694/pros-and-cons-of-different-integrators

# #if FORMAT in ("pdflatex", "latex")
===== The St\"{o}rmer-Verlet algorithm for the generalized model =====
# #else
===== The Stoermer-Verlet algorithm for the generalized model =====
# #endif
label{vib:model2x2:gen:StormerVerlet}

We can easily apply the ideas from Section ref{vib:model2x2:StormerVerlet} to
extend that method to the generalized model

!bt
\begin{align*}
v^{\prime} &= \frac{1}{m}(F(t)-s(u)-f(v)),\\
u^{\prime} &= v\tp
\end{align*}
!et
However, since the scheme is essentially centered differences for
the ODE system on a staggered mesh, we do not go into detail here,
but refer to Section ref{vib:ode2:staggered}.

===== A staggered Euler-Cromer scheme for a generalized model =====
label{vib:ode2:staggered}

The more general model for vibration problems,

!bt
\begin{equation}
mu'' + f(u') + s(u) = F(t),\quad u(0)=I,\ u'(0)=V,\ t\in (0,T],
\end{equation}
!et
can be rewritten as a first-order ODE system

!bt
\begin{align}
v' &= m^{-1}\left(F(t) - f(v) - s(u)\right),
label{vib:ode2:staggered:veq}\\
u' &= v\tp
label{vib:ode2:staggered:ueq}
\end{align}
!et
It is natural to introduce a staggered mesh (see Section ref{vib:model2x2:staggered}) and seek $u$ at mesh points $t_n$ (the numerical value is
denoted by $u^n$) and $v$ between mesh points at $t_{n+1/2}$ (the numerical
value is denoted by $v^{n+\half}$).
A centered difference approximation to (ref{vib:ode2:staggered:ueq})-(ref{vib:ode2:staggered:veq}) can then be written in operator notation as

!bt
\begin{align}
\lbrack D_tv &= m^{-1}\left(F(t) - f(v) - s(u)\right)\rbrack^n,
label{vib:ode2:staggered:dveq}\\
\lbrack D_t u &= v\rbrack^{n+\half}\tp
label{vib:ode2:staggered:dueq}
\end{align}
!et
Written out,

!bt
\begin{align}
\frac{v^{n+\half} - v^{n-\half}}{\Delta t}
&= m^{-1}\left(F^n - f(v^n) - s(u^n)\right),
label{vib:ode2:staggered:dveq2}\\
\frac{u^n - u^{n-1}}{\Delta t} &= v^{n+\half}\tp
label{vib:ode2:staggered:dueq2}
\end{align}
!et

With linear damping, $f(v)=bv$, we can use an arithmetic mean
for $f(v^n)$: $f(v^n)\approx = \half(f(v^{n-\half}) +
f(v^{n+\half}))$. The system
(ref{vib:ode2:staggered:dveq2})-(ref{vib:ode2:staggered:dueq2})
can then be solved with respect to the unknowns $u^n$ and $v^{n+\half}$:

!bt
\begin{align}
v^{n+\half} &= \left(1 + \frac{b}{2m}\Delta t\right)^{-1}\left(
v^{n-\half} + {\Delta t}
m^{-1}\left(F^n - {\half}f(v^{n-\half}) - s(u^n)\right)\right),
label{vib:ode2:staggered:v:scheme:lin}\\
u^n & = u^{n-1} + {\Delta t}v^{n-\half}\tp
label{vib:ode2:staggered:u:scheme:lin}
\end{align}
!et

In case of quadratic damping, $f(v)=b|v|v$, we can use a geometric mean:
$f(v^n)\approx b|v^{n-\half}|v^{n+\half}$. Inserting this approximation
in (ref{vib:ode2:staggered:dveq2})-(ref{vib:ode2:staggered:dueq2}) and
solving for the unknowns $u^n$ and $v^{n+\half}$ results in

!bt
\begin{align}
v^{n+\half} &= (1 + \frac{b}{m}|v^{n-\half}|\Delta t)^{-1}\left(
v^{n-\half} + {\Delta t}
m^{-1}\left(F^n - s(u^n)\right)\right),
label{vib:ode2:staggered:v:scheme:quad}\\
u^n & = u^{n-1} + {\Delta t}v^{n-\half}\tp
label{vib:ode2:staggered:u:scheme:quad}
\end{align}
!et

The initial conditions are derived at the end of
Section ref{vib:model2x2:staggered}:

!bt
\begin{align}
u^0 &= I,
label{vib:ode2:staggered:u02}\\
v^\half &= V - \half\Delta t\omega^2I
label{vib:ode2:staggered:v02}\tp
\end{align}
!et

[hpl: Must deal with two things: how to set initial conditions on $v$, and
how to make phase-space plots with $v$ at integer mesh points. See
article.]

===== The PEFRL 4th-order accurate algorithm =====
label{vib:ode2:PEFRL}

A variant of the Euler-Cromer type of algorithm, which provides an
error $\Oof{\Delta t^4}$ if $f(v)=0$, is called PEFRL
cite{PEFRL_2002}. This algorithm is very well suited for integrating
dynamic systems (especially those without damping) over very long time
periods. Define

!bt
\[ g(u,v) = \frac{1}{m}(F(t)-s(u)-f(v))\tp\]
!et
The algorithm is explicit and features these simple steps:

!bt
\begin{align}
u^{n+1,1} &= u^n       + \xi\Delta t v^n,\\
v^{n+1,1} &= v^n       + \half(1-2\lambda)\Delta t g(u^{n+1,1},v^n),\\
x^{n+1,2} &= x^{n+1,1} + \chi\Delta t v^{n+1,1},\\
v^{n+1,2} &= v^{n+1,1} + \lambda\Delta t g(u^{n+1,2}, v^{n+1,1}),\\
x^{n+1,3} &= x^{n+1,2} + (1-2(\chi + \xi))\Delta t v^{n+1,2},\\
v^{n+1,3} &= v^{n+1,2} + \lambda\Delta t g(u^{n+1,3}, v^{n+1,2}),\\
u^{n+1,4} &= u^{n+1,3} + \chi\Delta t v^{n+1,3},\\
v^{n+1}   &= v^{n+1,3} + \half(1-2\lambda)\Delta t g(u^{n+1,4},v^{n+1,3}),\\
u^{n+1}   &= u^{n+1,4} + \xi\Delta t v^{n+1}
\end{align}
!et
# Compare with eq 22 in article
The parameters $\xi$, $\lambda$, and $\xi$ have the values

!bt
\begin{align}
\xi &= 0.1720865590295143,\\
\lambda &= -0.09156203075515678,\\
\chi &= -0.1616217622107222
\end{align}
!et

======= Exercises and Problems =======

===== Problem: Use linear/quadratic functions for verification =====
label{vib:exer:undamped:verify:linquad}
file=vib_undamped_verify_mms

Consider the ODE problem

!bt
\[ u^{\prime\prime} + \omega^2u=f(t), \quad u(0)=I,\ u^{\prime}(0)=V,\ t\in(0,T]\tp\]
!et

!bsubex
Discretize this equation according to $[D_tD_t u + \omega^2 u = f]^n$ and
derive the equation for the first time step ($u^1$).

!bsol
For the requested discretization, we get
!bt
\[ \frac{u^{n+1} - 2u^n + u^{n-1}}{\Delta t^2} + \omega^2u^n = f^n\tp\]
!et
To derive the equation for $u^1$, we first find the expression for $u^{n+1}$ from the
discretized form of the equation. Isolating $u^{n+1}$, we get
!bt
\[ u^{n+1} = \left(2 - (\Delta t\omega)^2\right)u^n - u^{n-1} + \Delta t^2 f^n\tp\]
!et
With $n = 0$, this expression gives
!bt
\[ u^1 = \left(2 - (\Delta t\omega)^2\right)u^0 - u^{-1} + \Delta t^2 f^n\tp\]
!et

Here, however, we get a problem with $u^{-1}$, which appears on the right hand side.
To get around that problem, we realize that the initial condition $u^{\prime} = V$ might
be approximated by use of a centered difference approximation as
!bt
\[ \frac{u^1 - u^{-1}}{2\Delta t} = V,\]
!et
which means that
!bt
\[ u^{-1} = u^1 - 2\Delta t V\tp\]
!et
Inserting this expression for $u^{-1}$ into the expression for $u^1$, we get
!bt
\[ u^1 = \left(2 - (\Delta t\omega)^2\right)u^0 - (u^1 - 2\Delta t V) + \Delta t^2 f^n\tp\]
!et
Finally, after isolating $u^1$ on the left hand side, we arrive at
\[ u^1 = \left(1 - \frac{1}{2}(\Delta t\omega)^2\right)u^0 + \Delta t V + \frac{1}{2}\Delta t^2 f^n\tp\]
!esol
!esubex

!bsubex
For verification purposes, we use the method of manufactured solutions (MMS) with the
choice of $\uex(t)= ct+d$. Find restrictions on $c$ and $d$ from
the initial conditions. Compute the corresponding source term $f$.
Show that $[D_tD_t t]^n=0$ and use the fact
that the $D_tD_t$ operator is linear,
$[D_tD_t (ct+d)]^n = c[D_tD_t t]^n + [D_tD_t d]^n = 0$, to show that
$\uex$ is also a perfect solution of the discrete equations.

!bsol
The initial conditions $u(0)=I$ and $u^{\prime}(0)=V$ give demands
$\uex(0)=I$ and $\uex^{\prime}(0)=V$, which imply that
$d = I$ and {c = V}.

To compute the source term $f$, we insert the chosen solution $\uex$ into
the ODE. This gives
!bt
\[ 0 + \omega^2(ct+d)=f(t),\]
!et
which implies that
!bt
\[ f(t)=\omega^2(Vt+I)\tp\]
!et
To show that $[D_tD_t t]^n=0$, we proceed as

!bt
\begin{align}
[D_tD_t t]^n &= \frac{t^{n+1} - 2t^n + t^{n-1}}{\Delta t^2}, \nonumber \\
             &= \frac{(n+1)\Delta t - 2n\Delta t + (n-1)\Delta t}{\Delta t^2}, \nonumber \\
             &= \frac{n\Delta t + \Delta t - 2n\Delta t + n\Delta t - \Delta t}{\Delta t^2}, \nonumber \\
             &= 0\tp \nonumber
\end{align}
!et
Finally, we show that the chosen $\uex$ is also a perfect solution of the discrete equations.
If we start by inserting $\uex$ into

!bt
\[ [D_tD_t u + \omega^2u = f]^n,\]
!et
as well as the expression found for $f$.
We get

!bt
\[[D_tD_t (Vt+I) + \omega^2(Vt+I) = \omega^2(Vt+I)]^n,\]
!et
which can be rewritten as

!bt
\[ [D_tD_t (Vt+I)]^n + [\omega^2(Vt+I)]^n = [\omega^2(Vt+I)]^n\tp\]
!et
Now, since the first term here is zero, we see that the discrete equation is
fulfilled exactly for the chosen $\uex$ function.
!esol
!esubex

!bsubex
Use `sympy` to do the symbolic calculations above. Here is a
sketch of the program `vib_undamped_verify_mms.py`:

!bc pycod
import sympy as sym
V, t, I, w, dt = sym.symbols('V t I w dt')  # global symbols
f = None  # global variable for the source term in the ODE

def ode_source_term(u):
    """Return the terms in the ODE that the source term
    must balance, here u'' + w**2*u.
    u is symbolic Python function of t."""
    return sym.diff(u(t), t, t) + w**2*u(t)

def residual_discrete_eq(u):
    """Return the residual of the discrete eq. with u inserted."""
    R = ...
    return sym.simplify(R)

def residual_discrete_eq_step1(u):
    """Return the residual of the discrete eq. at the first
    step with u inserted."""
    R = ...
    return sym.simplify(R)

def DtDt(u, dt):
    """Return 2nd-order finite difference for u_tt.
    u is a symbolic Python function of t.
    """
    return ...

def main(u):
    """
    Given some chosen solution u (as a function of t, implemented
    as a Python function), use the method of manufactured solutions
    to compute the source term f, and check if u also solves
    the discrete equations.
    """
    print '=== Testing exact solution: %s ===' % u
    print "Initial conditions u(0)=%s, u'(0)=%s:" % \
          (u(t).subs(t, 0), sym.diff(u(t), t).subs(t, 0))

    # Method of manufactured solution requires fitting f
    global f  # source term in the ODE
    f = sym.simplify(ode_lhs(u))

    # Residual in discrete equations (should be 0)
    print 'residual step1:', residual_discrete_eq_step1(u)
    print 'residual:', residual_discrete_eq(u)

def linear():
    main(lambda t: V*t + I)

if __name__ == '__main__':
    linear()
!ec
Fill in the various functions such that the calls in the `main`
function works.

!bsol
This part of the code goes as follows:

@@@CODE exer-vib/vib_undamped_verify_mms.py fromto: import sympy@def linear

!esol
!esubex

!bsubex
The purpose now is to choose a quadratic function
$\uex = bt^2 + ct + d$ as exact solution. Extend the `sympy`
code above with a function `quadratic` for fitting `f` and checking
if the discrete equations are fulfilled. (The function is very similar
to `linear`.)

#Check with hand calculations that the `sympy` implementation
#is correct.

!bsol
Yes, a quadratic function will fulfill the discrete equations exactly.
The implementation becomes

@@@CODE exer-vib/vib_undamped_verify_mms.py fromto: def quadratic@def cubic
Calling `quadratic()` shows that the residual vanishes, and the quadratic
function is an exact solution of the discrete equations.
!esol
!esubex

!bsubex
Will a polynomial of degree three fulfill the discrete equations?

!bsol
We can easily make a test:

@@@CODE exer-vib/vib_undamped_verify_mms.py fromto: def cubic@def solver
When running the final code presented below, the printout shows that the
step1 residual for the cubic function is not zero.
!esol
!esubex

!bsubex
Implement a `solver` function for computing the numerical
solution of this problem.

!bsol
The `solver` function may take the form

@@@CODE exer-vib/vib_undamped_verify_mms.py fromto: def solver@def test_quadratic
We can verify the implementation by the following test function:

@@@CODE exer-vib/vib_undamped_verify_mms.py fromto: def test_quadratic@if __name
!esol
!esubex


!bsubex
Write a test function for checking that the quadratic solution
is computed correctly (to machine precision, but the
round-off errors accumulate and increase with $T$) by the `solver`
function.

!bsol
Here is the complete code for this exercise:

@@@CODE exer-vib/vib_undamped_verify_mms.py

!esol
!esubex


===== Exercise: Show linear growth of the phase with time =====
label{vib:exer:phase:err:growth}
file=vib_phase_error_growth

Consider an exact solution $I\cos (\omega t)$ and an
approximation $I\cos(\tilde\omega t)$.
Define the phase error as the time lag between the peak $I$
in the exact solution and the corresponding peak in the approximation
after $m$ periods of oscillations. Show that this phase error
is linear in $m$.

!bsol
From (ref{vib:ode1:tildeomega:series}) we have that
!bt
\begin{equation}
\tilde\omega = \omega\left( 1 + \frac{1}{24}\omega^2\Delta t^2\right)
+ \Oof{\Delta t^4}
\tp
\nonumber
\end{equation}
!et
Dropping the $\Oof{\Delta t^4}$ term, and since $\omega=\frac{2\pi}{P}$ and $\tilde\omega=\frac{2\pi}{\tilde P}$, we have that
!bt
\begin{equation}
\frac{2\pi}{\tilde P} \approx \frac{2\pi}{P}\left( 1 + \frac{1}{24}\omega^2\Delta t^2\right)
\tp
\nonumber
\end{equation}
!et
Now, $2\pi$ cancels and the remaining equation may be rewritten as
!bt
\begin{equation}
P - \tilde P \approx \frac{1}{24}\omega^2\Delta t^2
\tp
\nonumber
\end{equation}
!et
This implies that the periods differ by a constant. Since the exact and the numerical
solution start out identically, the phase error $P - \tilde P$ will become
$m\frac{1}{24}\omega^2\Delta t^2$ after $m$ periods, i.e. the phase error is linear in $m$.

!esol


===== Exercise: Improve the accuracy by adjusting the frequency =====
label{vib:exer:w:adjust}
file=vib_adjust_w

According to (ref{vib:ode1:tildeomega:series}), the numerical
frequency deviates from the exact frequency by a (dominating) amount
$\omega^3\Delta t^2/24 >0$. Replace the `w` parameter in the algorithm
in the `solver` function in `vib_undamped.py` by `w*(1 -
(1./24)*w**2*dt**2` and test how this adjustment in the numerical
algorithm improves the accuracy (use $\Delta t =0.1$ and simulate
for 80 periods, with and without adjustment of $\omega$).

# How does this go if

!bsol
We may take a copy of the `vib_undamped.py` file and edit the `solver`
function to

@@@CODE exer-vib/vib_adjust_w.py fromto: from numpy@def exact_solution

The modified code was run for 80 periods with, and without,
the given adjustment of $\omega$. A substantial difference in accuracy
was observed between the two,
showing that the frequency adjustment improves the situation.
!esol


===== Exercise: See if adaptive methods improve the phase error =====
label{vib:exer:undamped:adaptive}
file=vib_undamped_adaptive

Adaptive methods for solving ODEs aim at adjusting $\Delta t$ such
that the error is within a user-prescribed tolerance. Implement the
equation $u^{\prime\prime}+u=0$ in the "Odespy": "https://github.com/hplgit/odespy"
software. Use the example ref[from Section
ref{decay:fd2:adaptiveRK}][ in cite{Langtangen_decay}]["on adaptive
schemes": "${decay_book}/._book006.html#example-adaptive-runge-kutta-methods"
in cite{Langtangen_decay}].  Run the scheme with a very low
tolerance (say $10^{-14}$) and for a long time, check the number of
time points in the solver's mesh (`len(solver.t_all)`), and compare
the phase error with that produced by the simple finite difference
method from Section ref{vib:ode1:fdm} with the same number of (equally
spaced) mesh points. The question is whether it pays off to use an
adaptive solver or if equally many points with a simple method gives
about the same accuracy.

!bsol
Here is a code where we define the test problem, solve it by the
Dormand-Prince adaptive method from Odespy, and then call `solver`

@@@CODE exer-vib/vib_undamped_adaptive.py

The program may produce the plots seen in
the figure below,
which shows how the adaptive solution clearly outperforms the simpler method,
regardless of the accuracy level.

FIGURE: [fig-vib/vib_undamped_adaptive, width=800 frac=1.0]

!esol


===== Exercise: Use a Taylor polynomial to compute $u^1$ =====
label{vib:exer:step4b:alt}
file=vib_first_step

As an alternative to computing $u^1$ by (ref{vib:ode1:step4b}),
one can use a Taylor polynomial with three terms:

!bt
\[ u(t_1) \approx u(0) + u^{\prime}(0)\Delta t + {\half}u^{\prime\prime}(0)\Delta t^2\]
!et
With $u^{\prime\prime}=-\omega^2 u$ and $u^{\prime}(0)=0$, show that this method also leads to
(ref{vib:ode1:step4b}). Generalize the condition on $u^{\prime}(0)$ to
be $u^{\prime}(0)=V$ and compute $u^1$ in this case with both methods.

!bsol
With $u^{\prime\prime}(0)=-\omega^2 u(0)$ and $u^{\prime}(0)=0$, the given Taylor series
becomes
!bt
\[ u(t_1) \approx u(0) + {\half}(-\omega^2 u(0))\Delta t^2\]
!et
which may be written as
!bt
\[ u^1 \approx u^0 - {\half}\Delta t^2\omega^2 u^0\]
!et
but this is nothing but (ref{vib:ode1:step4b}).

Now, consider $u^{\prime}(0)=V$.
With a centered difference approximation, this initial condition becomes
!bt
\[ \frac{u^1 - u^{-1}}{2\Delta t} \approx V\]
!et
which implies that
!bt
\[ u^{-1} \approx u^1 - 2\Delta t V\]
!et
When $n=0$, (ref{vib:ode1:step4}) reads
!bt
\[ u^1 = 2u^0 - u^{-1} - \Delta t^2\omega^2 u^0\]
!et
Inserting the expression for $u^{-1}$, we get
!bt
\[ u^1 = 2u^0 - (u^1 - 2\Delta t V) - \Delta t^2\omega^2 u^0\]
!et
which implies that
!bt
\[ u^1 = u^0 + \Delta t V - \frac{1}{2}\Delta t^2\omega^2 u^0\]
!et
With the Taylor series approach, we now get
!bt
\[ u(t_1) \approx u(0) + V\Delta t + {\half}(-\omega^2 u(0))\Delta t^2\]
!et
which also gives
!bt
\[ u^1 = u^0 + \Delta t V - \frac{1}{2}\Delta t^2\omega^2 u^0\]
!et

!esol


===== Problem: Derive and investigate the velocity Verlet method =====

The velocity Verlet method for $u^{\prime\prime} + \omega^2u=0$ is
based on the following ideas:

 o step $u$ forward from $t_n$ to $t_{n+1}$ using a three-term Taylor
   series,
 o replace $u^{\prime\prime}$ by $-\omega^2u$
 o discretize $v^{\prime}=-\omega^2u$ by a Crank-Nicolson method.

Derive the scheme, implement it, and determine empirically the convergence rate.

#How can the scheme be extended to the general case $mu^{\prime\prime}
#+ f(u^{\prime}) + s(u) =F(t)$? No, that's too complicated because of
#the substitution in the Taylor series.

!bsol
Stepping $u$ forward from $t_n$ to $t_{n+1}$ using a three-term Taylor
series gives

!bt
\[ u(t_{n+1}) = u(t_n) + u^{\prime}(t_n)\Delta t + \frac{1}{2}u^{\prime\prime}(t_n)\Delta t^2\tp\]
!et
Using $u^{\prime}=v$ and $u^{\prime\prime}=-\omega^2u$, we get the updating formula

!bt
\[ u^{n+1} = u^n + v^n\Delta t - \frac{1}{2}\Delta t^2\omega^2u^n\tp\]
!et
Second, the first-order equation for $v$,

!bt
\[ v^{\prime}=-\omega^2u,\]
!et
is discretized by a centered difference in a Crank-Nicolson fashion at
$t_{n+\frac{1}{2}}$:

!bt
\[ \frac{v^{n+1}-v^n}{\Delta t} = -\omega^2\frac{1}{2}(u^n + u^{n+1})\tp\]
!et
To summarize, we have the scheme

!bt
\begin{align}
u^{n+1} &= u^n + v^n\Delta t - \frac{1}{2}\Delta t^2\omega^2u^n,\\
v^{n+1} &= v^n -\frac{1}{2}\Delta t\omega^2 (u^n + u^{n+1}),
\end{align}
!et
known as the velocity Verlet algorithm.
Observe that this scheme is explicit since $u^{n+1}$ in the second
equation is already computed by the first equation.

The algorithm can be straightforwardly implemented as shown below:

@@@CODE exer-vib/vib_undamped_velocity_Verlet.py fromto: from vib_undamped@if __name
We provide the option that this `solver` function returns the same data
as the `solver` function from Section ref{vib:impl1:solver} (if `return_v`
is `False`), but alternatively, it may return `v` along with `u` and `t`.

The error in the Taylor series expansion behind the first equation
is $\Oof{\Delta t^3}$, while the error
in the central difference for $v$ is $\Oof{\Delta t^2}$.  The overall
error is then no better than $\Oof{\Delta t^2}$, which can be verified
empirically using the `convergence_rates` function from
Section ref{vib:ode1:verify}:

!bc pyshell
>>> import vib_undamped_velocity_Verlet as m
>>> m.convergence_rates(4, solver_function=m.solver)
[2.0036366687367346, 2.0009497328124835, 2.000240105995295]
!ec
The output confirms that the overall convergence rate is 2.
!esol

===== Problem: Find the minimal resolution of an oscillatory function =====
# Short: Find the largest relevant value of $\omega\Delta t$

label{vib:exer:wdt:limit}
file=vib_largest_wdt

Sketch the function on a given mesh which has the highest possible
frequency. That is, this oscillatory ``cos-like'' function has its
maxima and minima at every two grid points.  Find an expression for
the frequency of this function, and use the result to find the largest
relevant value of $\omega\Delta t$ when $\omega$ is the frequency
of an oscillating function and $\Delta t$ is the mesh spacing.

!bsol
The smallest period must be $2\Delta t$. Since the period $P$ is related
to the angular frequency $\omega$ by $P=2\pi/\omega$, it means that
$\omega = \frac{2\pi}{2\Delta t} = \frac{\pi}{\Delta t}$ is the smallest
meaningful angular frequency.
This further means that the largest value for $\omega\Delta t$ is $\pi$.

!esol


===== Exercise: Visualize the accuracy of finite differences for a cosine function =====
# Short: Visualize the accuracy of finite differences

label{vib:exer:fd:exp:plot}
file=vib_plot_fd_exp_error

We introduce the error fraction

!bt
\[ E = \frac{[D_tD_t u]^n}{u^{\prime\prime}(t_n)} \]
!et
to measure the error in the finite difference approximation $D_tD_tu$ to
$u^{\prime\prime}$.
Compute $E$
for the specific choice of a cosine/sine function of the
form $u=\exp{(i\omega t)}$ and show that

!bt
\[ E = \left(\frac{2}{\omega\Delta t}\right)^2
\sin^2(\frac{\omega\Delta t}{2})
\tp
\]
!et
Plot $E$ as a function of $p=\omega\Delta t$. The relevant
values of $p$ are $[0,\pi]$ (see Exercise ref{vib:exer:wdt:limit}
for why $p>\pi$ does not make sense).
The deviation of the curve from unity visualizes the error in the
approximation. Also expand $E$ as a Taylor polynomial in $p$ up to
fourth degree (use, e.g., `sympy`).

!bsol
!bt
\begin{align}
E &= \frac{[D_tD_t u]^n}{u^{\prime\prime}(t_n)}, \nonumber \\
  &= \frac{u^{n+1} - 2u^n + u^{n-1}}{u^{\prime\prime}(t_n)\Delta t^2}, \nonumber
\end{align}
!et
Since $u(t)=\exp{(i\omega t)}$, we have that $u^{\prime}(t)=i\omega\exp{(i\omega t)}$
and $u^{\prime\prime}(t)=(i\omega)^2\exp{(i\omega t)}=-\omega^2\exp{(i\omega t)}$, so we may proceed with $E$ as

!bt
\begin{align}
E &= \frac{e^{i\omega(t_n+\Delta t)} - 2e^{i\omega t_n} + e^{i\omega(t_n-\Delta t)}}{-\omega^2e^{i\omega t_n}\Delta t^2}, \nonumber \\
  &=\frac{e^{i\omega t_n}e^{i\omega \Delta t} -2e^{i\omega t_n} + e^{i\omega t_n}e^{-i\omega\Delta t}}{-\omega^2e^{i\omega t_n}\Delta t^2}, \nonumber \\
  &= \frac{e^{i\omega\Delta t} - 2 + e^{-i\omega\Delta t}}{-\omega^2 \Delta t^2}, \nonumber \\
  &= \frac{1}{-\omega^2 \Delta t^2}\frac{4}{4}\left(e^{i\omega\Delta t} - 2 + e^{-i\omega\Delta t}\right), \nonumber \\
  &= \left(\frac{2}{\omega\Delta t}\right)^2 \left(-\frac{e^{i\omega\Delta t} - 2 + e^{-i\omega\Delta t}}{4}\right), \nonumber \\
  &= \left(\frac{2}{\omega\Delta t}\right)^2 \left(-\frac{1}{2}\left(\frac{1}{2}e^{i\omega\Delta t} + e^{-i\omega\Delta t} - 1\right)\right), \nonumber \\
  &= \left(\frac{2}{\omega\Delta t}\right)^2 \left(-\frac{1}{2}\left( \cos(\omega\Delta t) - 1\right)\right). \nonumber
\end{align}
!et
Now, since $\cos(\omega\Delta t)=1-2\sin^2\left(\frac{\omega\Delta t}{2}\right)$, we finally get
!bt
\begin{align}
E &= \left(\frac{2}{\omega\Delta t}\right)^2 \left(-\frac{1}{2}\left( \left(1-2\sin^2\left(\frac{\omega\Delta t}{2}\right)\right) - 1\right)\right), \nonumber \\
  &= \left(\frac{2}{\omega\Delta t}\right)^2 \sin^2\left(\frac{\omega\Delta t}{2}\right). \nonumber
\end{align}
!et

@@@CODE exer-vib/vib_plot_fd_exp_error.py

From the plot seen below, we realize
how the error fraction $E$ deviates from unity as $p$ grows.

FIGURE: [fig-vib/error_fraction, width=600 frac=1.0]

!esol


===== Exercise: Verify convergence rates of the error in energy =====
label{vib:exer:energy:convrate}
file=test_error_conv

We consider the ODE problem $u^{\prime\prime} + \omega^2u=0$, $u(0)=I$, $u^{\prime}(0)=V$,
for $t\in (0,T]$. The total energy of the solution
$E(t)=\half(u^{\prime})^2 + \half\omega^2 u^2$ should stay
constant.
The error in energy can be computed as explained in
Section ref{vib:model1:energy}.

Make a test function in a separate file, where code from
`vib_undamped.py` is imported, but the `convergence_rates` and
`test_convergence_rates` functions are copied and modified to also
incorporate computations of the error in energy and the convergence
rate of this error. The expected rate is 2, just as for the solution
itself.

!bsol
The complete code with test functions goes as follows.

@@@CODE exer-vib/test_error_conv.py

!esol

===== Exercise: Use linear/quadratic functions for verification  =====
label{vib:exer:verify:gen:linear}
file=vib_verify_mms

This exercise is a generalization of Problem
ref{vib:exer:undamped:verify:linquad} to the extended model problem
(ref{vib:ode2}) where the damping term is either linear or quadratic.
Solve the various subproblems and see how the results and problem
settings change with the generalized ODE in case of linear or
quadratic damping. By modifying the code from Problem
ref{vib:exer:undamped:verify:linquad}, `sympy` will do most
of the work required to analyze the generalized problem.

!bsol
With a linear spring force, i.e. $s(u)=cu$ (for constant $c$),
our model problem becomes

!bt
\begin{equation}
mu^{\prime\prime} + f(u^{\prime}) + cu = F(t),\quad u(0)=I,\ u^{\prime}(0)=V,\ t\in (0,T]
\tp
\nonumber
\end{equation}
!et
First we consider linear damping, i.e., when $f(u^{\prime}) =
bu^{\prime}$, and follow the text in Section
ref{vib:ode2:fdm:flin}. Discretizing the equation according to

!bt
\begin{equation}
[mD_tD_t u + f(D_{2t}u) + cu = F]^n,
\nonumber
\end{equation}
!et
implies that

!bt
\begin{equation}
m\frac{u^{n+1}-2u^n + u^{n-1}}{\Delta t^2}
+ b\frac{u^{n+1}-u^{n-1}}{2\Delta t} + cu^n = F^n.
\nonumber
\end{equation}
!et
The explicit formula for $u$ at each
new time level then becomes

!bt
\begin{equation}
u^{n+1} = (2mu^n + (\frac{b}{2}\Delta t - m)u^{n-1} +
\Delta t^2(F^n - cu^n))(m + \frac{b}{2}\Delta t)^{-1}
\nonumber
\tp
\end{equation}
!et
For the first time step, we use $n=0$ and a centered difference approximation for the
initial condition on the derivative. This gives

!bt
\begin{equation}
u^1 = u^0 + \Delta t\, V
+ \frac{\Delta t^2}{2m}(-bV - cu^0 + F^0)
\tp
\nonumber
\end{equation}
!et

Next, we consider quadratic damping, i.e., when
$f(u^{\prime})=bu^{\prime}|u^{\prime}|$, and follow the
text in Chapter ref{vib:ode2:fdm:fquad}. Discretizing the
equation according to
!bt
\begin{equation}
[mD_tD_t u + bD_{2t}u|D_{2t}u| + cu = F]^n\tp
\nonumber
\end{equation}
!et
gives us
!bt
\begin{equation}
m\frac{u^{n+1}-2u^n + u^{n-1}}{\Delta t^2}
+ b\frac{u^{n+1}-u^n}{\Delta t}\frac{|u^n-u^{n-1}|}{\Delta t}
+ cu^n = F^n.
\nonumber
\end{equation}
!et
We solve for $u^{n+1}$ to get the explicit updating formula as
!bt
\begin{align}
u^{n+1} &=  \left( m + b|u^n-u^{n-1}|\right)^{-1}\times \nonumber\\
& \qquad \left(2m u^n - mu^{n-1} + bu^n|u^n-u^{n-1}| + \Delta t^2 (F^n - cu^n)
\right)
\tp
\nonumber
\end{align}
!et
and the equation for the first time step as
!bt
\begin{equation}
u^1 = u^0 + \Delta t V + \frac{\Delta t^2}{2m}\left(-bV|V| - cu^0 + F^0\right)
\tp
\nonumber
\end{equation}
!et

Turning to verification with MMS and $u_e(t)=ct+d$, we get $d=I$ and $c=V$ independent
of the damping term, so these parameter values stay as for the undamped case.

Proceeding with linear damping, we get from chapter ref{vib:ode2:verify} that
!bt
\begin{equation}
F(t) = bV + c(Vt + I)\tp
\nonumber
\end{equation}
!et
(Note that there are two different c parameters here, one from $u_e=ct+d$ and one from the spring force $cu$.
The first one disappears, however, as it is switched with $V$.)

To show that $u_e$ is a perfect solution also to the discrete equations, we insert $u_e$ and $F$ into
!bt
\begin{equation}
[mD_tD_t u + bD_{2t}u + cu = F]^n\tp
\nonumber
\end{equation}
!et
This gives
!bt
\begin{equation}
[mD_tD_t (Vt+I) + bD_{2t}(Vt+I) + c(Vt+I) = bV + c(Vt + I)]^n,
\nonumber
\end{equation}
!et
which may be split up as
!bt
\begin{equation}
m[D_tD_t (Vt+I)]^n + b[D_{2t}(Vt+I)]^n + c[(Vt+I)]^n = b[V]^n + c[(Vt + I)]^n.
\nonumber
\end{equation}
!et
Simplifying, we note that the first term is zero and that $c[(Vt+I)]^n$ appears with the
same sign on each side of the equation. Thus, dropping these terms, and cancelling the common
factor $b$, we are left with
!bt
\begin{equation}
[D_{2t}(Vt+I)]^n = [V]^n.
\nonumber
\end{equation}
!et
It therefore remains to show that $[D_{2t}(Vt+I)]^n$ is equal to $[V]^n = V$. We write out
the left hand side as
!bt
\begin{align}
[D_{2t}(Vt+I)]^n &= \frac{(Vt_{n+1}+I) - (Vt_{n-1}+I)}{2\Delta t} \nonumber\\
                 &= \frac{V(t_{n+1}-t_{n-1})}{2\Delta t} \nonumber\\
                 &= \frac{V((t_n + \Delta t) - (t_n - \Delta t))}{2\Delta t} \nonumber\\
                 &= V, \nonumber
\nonumber
\end{align}
!et
which shows that the two sides of the equation are equal and that the discrete equations
are fulfilled exactly for the given $u_e$ function.

If the damping is rather quadratic, we find from chapter ref{vib:ode2:verify} that
!bt
\begin{equation}
F(t) = b|V|V + c(Vt + I)\tp
\nonumber
\end{equation}
!et
As with linear damping, we show that $u_e$ is a perfect solution also to the discrete equations
by inserting $u_e$ and $F$ into
!bt
\begin{equation}
[mD_tD_t u + bD_{2t}u|D_{2t}u| + cu = F]^n\tp
\nonumber
\end{equation}
!et
We then get
!bt
\begin{equation}
[mD_tD_t (Vt+I) + bD_{2t}(Vt+I)|D_{2t}(Vt+I)| + c(Vt+I) = b|V|V + c(Vt+I)]^n,
\nonumber
\end{equation}
!et
which simplifies to
!bt
\begin{equation}
[bD_{2t}(Vt+I)|D_{2t}(Vt+I)| = b|V|V]^n
\nonumber
\end{equation}
!et
and further to
!bt
\begin{equation}
[D_{2t}(Vt+I)]^n [|D_{2t}(Vt+I)|]^n = |V|V
\nonumber
\end{equation}
!et
which simply states that
!bt
\begin{equation}
V|V| = |V|V\tp
\nonumber
\end{equation}
!et
Thus, $u_e$ fulfills the discrete equations exactly also when the damping term
is quadratic.

When the exact solution is changed to become quadratic or cubic, the situation is more complicated.

For a quadratic solution $u_e$ combined with (zero damping or) linear damping, the output from the program below shows that the discrete equations are fulfilled exactly. However, this is not the case with nonlinear damping, where only the first step gives zero residual.

For a cubic solution $u_e$, we get a nonzero residual for (zero damping and) linear and nonlinear damping.

@@@CODE exer-vib/vib_verify_mms.py

!esol


===== Exercise: Use an exact discrete solution for verification =====
label{vib:exer:discrete:omega}
file=test_vib_undamped_exact_discrete_sol

Write a test function in a separate file
that employs the exact discrete solution
(ref{vib:ode1:un:exact}) to verify the implementation of the
`solver` function in the file `vib_undamped.py`.

!bsol
The code goes like this:

@@@CODE exer-vib/test_vib_undamped_exact_discrete_sol.py fromto: from vib_undamped@

!esol

===== Exercise: Use analytical solution for convergence rate tests =====
label{vib:exer:conv:rate}
file=vib_conv_rate

The purpose of this exercise is to perform convergence tests of the
problem (ref{vib:ode2}) when $s(u)=cu$, $F(t)=A\sin\phi t$ and there
is no damping.  Find the complete analytical solution to the problem
in this case (most textbooks on mechanics or ordinary differential
equations list the various elements you need to write down the exact
solution, or you can use symbolic tools like `sympy` or `wolframalpha.com`).
Modify the `convergence_rate` function from the
`vib_undamped.py` program to perform experiments with the extended
model.  Verify that the error is of order $\Delta t^2$.

!bsol
The code:
@@@CODE exer-vib/vib_conv_rate.py

The output from the program shows that $r$ approaches 2.
!esol

===== Exercise: Investigate the amplitude errors of many solvers =====
label{vib:exer:undamped:odespy}
file=vib_amplitude_errors

Use the program `vib_undamped_odespy.py` from Section
ref{vib:model2x2:compare} (utilize the function `amplitudes`) to investigate
how well famous methods for 1st-order ODEs can preserve the amplitude of $u$ in undamped
oscillations.  Test, for example, the 3rd- and 4th-order Runge-Kutta
methods (`RK3`, `RK4`), the Crank-Nicolson method (`CrankNicolson`),
the 2nd- and 3rd-order Adams-Bashforth methods (`AdamsBashforth2`,
`AdamsBashforth3`), and a 2nd-order Backwards scheme
(`Backward2Step`).  The relevant governing equations are listed in
the beginning of Section ref{vib:model2x2}.

Running the code, we get the plots seen in Figure ref{vib:exer:fig:ampl_RK34},
ref{vib:exer:fig:ampl_CNB2}, and ref{vib:exer:fig:ampl_AB}. They
show that `RK4` is superior to the others, but that also `CrankNicolson` performs well. In fact, with `RK4` the amplitude changes by less than $0.1$ per cent over the interval.

FIGURE: [fig-vib/Amplitudes_RK3_RK4, width=600 frac=1.0] The amplitude as it changes over 100 periods for RK3 and RK4. label{vib:exer:fig:ampl_RK34}

FIGURE: [fig-vib/Amplitudes_CrankNicolson_Backward2Step, width=600 frac=1.0] The amplitude as it changes over 100 periods for Crank-Nicolson and Backward 2 step. label{vib:exer:fig:ampl_CNB2}

FIGURE: [fig-vib/Amplitudes_AdamsBashforth2_AdamsBashforth3, width=600 frac=1.0] The amplitude as it changes over 100 periods for Adams-Bashforth 2 and 3. label{vib:exer:fig:ampl_AB}


!bsol
We modify the proposed code to the following:

@@@CODE exer-vib/vib_amplitude_errors.py

!esol


===== Problem: Minimize memory usage of a vibration solver =====
label{vib:exer:memsave}
file=vib_memsave

The program "`vib.py`": "${src_vib}/vib.py" stores the complete
solution $u^0,u^1,\ldots,u^{N_t}$ in memory, which is convenient for
later plotting.  Make a memory minimizing version of this program
where only the last three $u^{n+1}$, $u^n$, and $u^{n-1}$ values are
stored in memory.  Write each computed $(t_{n+1}, u^{n+1})$ pair to
file.  Visualize the data in the file (a cool solution is to read one
line at a time and plot the $u$ value using the line-by-line plotter
in the `visualize_front_ascii` function - this technique makes it
trivial to visualize very long time simulations).

!bsol
Here is the complete program:

@@@CODE exer-vib/vib_memsave.py

!esol

===== Exercise: Implement the Euler-Cromer scheme for the generalized model =====
label{vib:exer:EC_vs_centered}
file=vib_EulerCromer

We consider the generalized model problem

!bt
\[ mu'' + f(u') + s(u) = F(t),\quad u(0)=I,\ u'(0)=V\tp\]
!et

!bsubex
Implement the Euler-Cromer method from Section ref{vib:ode2:EulerCromer}.

!bsol
A suitable function is

@@@CODE exer-vib/vib_EulerCromer.py fromto: import numpy@def test_
!esol
!esubex

!bsubex
We expect the Euler-Cromer method to have first-order convergence rate.
Make a unit test based on this expectation.

!bsol
We may use SymPy to derive a problem based on a manufactured solution
$u=3\cos t$. Then we may run some $\Delta t$ values, compute the error
divided by $\Delta t$, and check that this ratio remains approximately
constant. (An alternative is to compute true convergence rates and check
that they are close to unity.)

@@@CODE exer-vib/vib_EulerCromer.py fromto: def test_@def demo
!esol
!esubex

!bsubex
Consider a system with $m=4$, $f(v)=b|v|v$, $b=0.2$, $s=2u$, $F=0$.
Compute the solution using the centered difference scheme
from Section ref{vib:ode2:fdm:flin} and the Euler-Cromer scheme
for the longest possible time step $\Delta t$. We can use the
result from the case without damping, i.e., the largest $\Delta t= 2/\omega$,
$\omega\approx
\sqrt{0.5}$ in this case, but since $b$ will modify the frequency, we
take the longest possible time step as a safety factor 0.9 times $2/\omega$.
Refine $\Delta t$ three times by a factor of two and compare the
two curves.

!bsol
We rely on the module `vib` for the implementation of the method
from Section ref{vib:ode2:fdm:flin}. A suitable function for making
the comparisons is then

@@@CODE exer-vib/vib_EulerCromer.py fromto: def demo@if __name
!esol
!esubex

===== Exercise: Implement the PEFRL algorithm =====
label{vib:exer:gen:PEFRL}
file=vib_PEFRL

We consider the motion of a planet around a star as modeled in
Section ref{vib:app:gravitation}. The simplified case where one
mass is very much bigger than the other and one object is at rest,
results in the scaled ODE model

!bt
\begin{align*}
\ddot x + (x^2 + y^2)^{3/2}x & = 0,\\
\ddot y + (x^2 + y^2)^{3/2}y & = 0\tp
\end{align*}
!et

!bsubex
It is easy to show that $x(t)$ and $y(t)$ goes like sine and cosine
functions. Use this idea to derive the exact solution.

!bsol
We may assume $x=C_x\cos(\omega t)$ and $y=C_y\sin(\omega t)$ for
constants $C_x,$, $C_y$, and $\omega$. Inserted in the equations, we
see that $\omega =1$. The initial conditions determine the other
constants, which we may choose as $C_x=C_y=1$ (the object starts
at $(1,0)$ with a velocity $(0,1)$). The motion is a perfect circle,
which should last forever.
!esol
!esubex

!bsubex
A planet may orbit a star for billion of years. We are now interested
in how accurate methods we actually need for such calculations.
First, we need to determine what the time interval of interest is in
scaled units. Take the earth and sun as typical objects and find
the characteristic time used in the scaling of the equations
($t_c = \sqrt{L^3/(mG)}$, where $m$ is the mass of the sun, $L$ is the
distance between the sun and the earth, and $G$ is the gravitational
constant. Find the scaled time interval corresponding to one billion years.

!bsol
According to "Wikipedia": "https://en.wikipedia.org/wiki/Solar_mass",
the mass of the sun is approximately $2\cdot 10^{30}$ kg. This
is 332946 times the mass of the sun, implying that the
dimensionless constant $\alpha = 3\cdot 10^{-6}$. With
$G=6.674\cdot 10^{-11}\hbox{ Nm}^2/\hbox{kg}^2$, and the
"sun-earth distance": "https://en.wikipedia.org/wiki/Astronomical_unit"
as (approximately) 150 million km, we have $t_c \approx 160 000$ s.
[hpl: This is just 1.85 days!]
!esol
!esubex

!bsubex
Make a solver based on Odespy for the current problem.
Run the 4-th order Runge-Kutta method for the time interval in b).
What is the deviation of the orbit after one billion years?
The answer depends heavily on the size of the time step. Try to establish
an empirical formula for the deviation of the orbit as a function of
$\Delta t$.
[hpl: This part may not be feasible at all. RK4 may run out of the orbit
after not so many years. It all depends on how small $\Delta t$
we can afford.]
!esubex

!bsubex
Implement a solver based on the PEFRL method from
Section ref{vib:ode2:PEFRL}. Verify its 4th-order convergence
using an equation $u'' + u = 0$.

!bsol
Here is a solver function:

@@@CODE exer-vib/vib_PEFRL.py fromto: import numpy@
Can take the verification from `exer-vib/vib_EulerCromer.py`.
!esol
!esubex

!bsubex
Run the PEFRL method on the planet-star problem and establish an
empirical relation for the deviation of the orbit as a function
of $\Delta t$. Is it feasible on today's computers to
simulate the planetary motion for one billion years?
!esubex

!bremarks
This exercise investigates whether it is feasible to predict
planetary motion for the life time of a solar system.
!eremarks

===== Exercise: Implement the solver via classes =====
label{vib:exer:gen:class}
file=vib_class

Reimplement the `vib.py` program using a class `Problem` to hold all
the physical parameters of the problem, a class `Solver` to hold the
numerical parameters and compute the solution, and a class
`Visualizer` to display the solution.

!bhint
Use the ideas and examples ref[from Section ref{decay:prog:se:class}
and ref{decay:prog:se:class2}][ in cite{Langtangen_decay}][for an "ODE
model":
"${decay_book}/._book009.html#classes-for-problem-and-solution-method"
in cite{Langtangen_decay}].  More specifically, make a superclass
`Problem` for holding the scalar physical parameters of a problem and
let subclasses implement the $s(u)$ and $F(t)$ functions as methods.
Try to call up as much existing functionality in `vib.py` as possible.
!ehint

!bsol
The complete code looks like this.

@@@CODE exer-vib/vib_class.py

!esol



===== Problem: Interpret $[D_tD_t u]^n$ as a forward-backward difference =====
label{vib:exer:DtDt:asDtpDtm}
file=vib_DtDt_fw_bw

Show that the difference $[D_t D_tu]^n$ is equal to $[D_t^+D_t^-u]^n$
and $D_t^-D_t^+u]^n$. That is, instead of applying a centered difference
twice one can alternatively apply a mixture of forward and backward
differences.

!bsol
!bt
\begin{align}
[D_t^+D_t^-u]^n &= [D_t^+\left(\frac{u^n - u^{n-1}}{\Delta t}\right)]^n \nonumber\\
                 &= [\left(\frac{u^{n+1} - u^n}{\Delta t}\right) - \left(\frac{u^n - u^{n-1}}{\Delta t}\right)]^n  \nonumber\\
                 &= \frac{u^{n+1}-2u^n+u^{n-1}}{\Delta t^2} \nonumber\\
                 &= [D_t D_tu]^n. \nonumber
\end{align}
!et
Similarly, we get that
!bt
\begin{align}
[D_t^-D_t^+u]^n &= [D_t^-\left(\frac{u^{n+1} - u^n}{\Delta t}\right)]^n \nonumber\\
                 &= [\left(\frac{u^{n+1} - u^n}{\Delta t}\right) - \left(\frac{u^n - u^{n-1}}{\Delta t}\right)]^n  \nonumber\\
                 &= \frac{u^{n+1}-2u^n+u^{n-1}}{\Delta t^2} \nonumber\\
                 &= [D_t D_tu]^n. \nonumber
\end{align}
!et

!esol


===== Problem: Use a backward difference for the damping term =====
label{vib:exer:quad:damping:bw}
file=vib_gen_bwdamping

As an alternative to discretizing the damping terms $\beta u^{\prime}$ and
$\beta |u^{\prime}|u^{\prime}$ by centered differences, we may apply
backward differences:

!bt
\begin{align*}
[u^{\prime}]^n &\approx [D_t^-u]^n,\\
& [|u^{\prime}|u^{\prime}]^n\\
&\approx [|D_t^-u|D_t^-u]^n\\
&= |[D_t^-u]^n|[D_t^-u]^n\tp
\end{align*}
!et
The advantage of the backward difference is that the damping term is
evaluated using known values $u^n$ and $u^{n-1}$ only.
Extend the "`vib.py`": "${src_vib}/vib.py" code with a scheme based
on using backward differences in the damping terms. Add statements
to compare the original approach with centered difference and the
new idea launched in this exercise. Perform numerical experiments
to investigate how much accuracy that is lost by using the backward
differences.


!bsol

The new discretization approach of the linear and quadratic damping
terms calls for new derivations of the updating formulas (for $u$) in
the solver. Since backward difference approximations will be used for
the damping term, we may also use this approximation for the initial
condition on $u^{\prime}(0)$ without deteriorating the convergence
rate any further. Note that introducing backward difference
approximations for the damping term make our computational schemes
first order, as opposed to the original second order schemes which
used central difference approximations also for the damping terms. The
motivation for also using a backward difference approximation for the
initial condition on $u^{\prime}(0)$, is simply that the computational
schemes get much simpler.

With linear damping, the new discretized form of the equation reads

!bt
\begin{equation}
m\frac{u^{n+1}-2u^n+u^{n-1}}{\Delta t^2} + b\frac{u^n - u^{n-1}}{\Delta t} + s(u^n) = F^n,
\nonumber
\end{equation}
!et
which gives us

!bt
\begin{equation}
u^{n+1} = \left(2-\frac{\Delta t b}{m}\right)u^n + \frac{\Delta t^2}{m}\left(F^n - s(u^n)\right) + \left(\frac{\Delta t b}{m} - 1\right)u^{n-1}.
\nonumber
\end{equation}
!et
With $n=0$, the updating formula becomes

!bt
\begin{equation}
u^1 = \left(2-\frac{\Delta t b}{m}\right)u^0 + \frac{\Delta t^2}{m}\left(F^0 - s(u^0)\right) + \left(\frac{\Delta t b}{m} - 1\right)u^{-1},
\nonumber
\end{equation}
!et
which requires some further elaboration because of the unknown $u^{-1}$. We handle this by discretizing the initial condition $u^{\prime}(0) = V$ by a backward difference approximation as

!bt
\begin{equation}
\frac{u^0 - u^{-1}}{\Delta t} = V,
\nonumber
\end{equation}
!et
which implies that

!bt
\begin{equation}
u^{-1} = u^0 - \Delta t V.
\nonumber
\end{equation}
!et
Inserting this expression for $u^{-1}$ in the updating formula for $u^{n+1}$, and simplifying,
gives us the following special formula for the first time step:

!bt
\begin{equation}
u^1 = u^0 + \Delta t V + \frac{\Delta t^2}{m}\left(-bV - s(u^0) + F^0\right).
\nonumber
\end{equation}
!et
Switching to quadratic damping, the new discretized form of the equations becomes

!bt
\begin{equation}
m\frac{u^{n+1}-2u^n+u^{n-1}}{\Delta t^2} + b|\frac{u^n - u^{n-1}}{\Delta t}|\frac{u^n - u^{n-1}}{\Delta t} + s(u^n) = F^n,
\nonumber
\end{equation}
!et
which leads to

!bt
\begin{equation}
u^{n+1} = 2u^n - u^{n-1} - \frac{b}{m}|u^n - u^{n-1}|(u^n - u^{n-1}) + \frac{\Delta t^2}{m}\left(F^n - s(u^n)\right).
\nonumber
\end{equation}
!et
With $n=0$, this updating formula becomes

!bt
\begin{equation}
u^1 = 2u^0 - u^{-1} - \frac{b}{m}|u^0 - u^{-1}|(u^0 - u^{-1}) + \frac{\Delta t^2}{m}\left(F^0 - s(u^0)\right).
\nonumber
\end{equation}
!et
Again, we handle the unknown $u^{-1}$ via the same expression as above, which be derived from a backward difference approximation to the initial condition on the derivative. Inserting this expression for $u^{-1}$ and simplifying, gives the special updating formula for $u^1$ as

!bt
\begin{equation}
u^1 = u^0 + \Delta t V + \frac{\Delta t^2}{m}\left(-b|V|V - s(u^0) + F^0\right).
\nonumber
\end{equation}
!et
We implement these new computational schemes in a new solver function
`solver_bwdamping`, so that the discrete solution for $u$ can be found
by both the original and the new solver. The difference between the
two different solutions is then visualized in the same way as the
original solution in `main`.

The convergence rates computed in `test_mms` demonstrates that our
scheme now is a first order scheme, as $r$ is seen to approach 1.0
with decreasing $\Delta t$.

Both solvers reproduce a constant solution exactly (within machine
precision), whereas sinusoidal and quadratic solutions differ, as
should be expected after comparing the schemes. Pointing out the
``best'' approach is difficult: the backward differences yield a much
simpler mathematical problem to be solved, while the more complicated
method converges faster and gives more accuracy for the same cost. On
the other hand, the backward differences can yield any reasonable
accuracy by lowering $\Delta t$, and the results are obtained within a
few seconds on a laptop.

Here is the complete computer code, arising from copying `vib.py` and changing
the functions that have to be changed:

@@@CODE exer-vib/vib_gen_bwdamping.py

Here is a comparison of standard method (2nd order) and backward differences for damping (1st order) for 10 (left) and 40 (right) time steps per period:

FIGURE: [fig-vib/vib_gen_bwdamping, width=800 frac=1]

!esol


===== Exercise: Analysis of the Euler-Cromer scheme =====
label{vib:exer:EulerCromer:analysis}

The Euler-Cromer scheme for the model problem
$u^{\prime\prime} + \omega^2 u =0$, $u(0)=I$, $u^{\prime}(0)=0$, is given in
(ref{vib:model2x2:EulerCromer:ueq1b})-(ref{vib:model2x2:EulerCromer:veq1b}).
Find the exact discrete solutions of this scheme and show that the solution
for $u^n$ coincides with that found in Section ref{vib:ode1:analysis}.

!bhint
Use an ``ansatz'' $u^n=I\exp{(i\tilde\omega\Delta t\,n)}$ and
$v^n=qu^n$, where $\tilde\omega$ and $q$ are unknown parameters. The
following formula is handy:

!bt
\[ \e^{i\tilde\omega\Delta t} + e^{i\tilde\omega(-\Delta t)} - 2
= 2\left(\cosh(i\tilde\omega\Delta t) -1 \right)
=-4\sin^2(\frac{\tilde\omega\Delta t}{2})\tp\]
!et
!ehint

!bsol
We follow the ideas in Section ref{vib:ode1:analysis}. Inserting
$u^n=I\exp{(i\tilde\omega\Delta t\,n)}$ and
$v^n=qu^n$ in
(ref{vib:model2x2:EulerCromer:ueq1b})-(ref{vib:model2x2:EulerCromer:veq1b})
and dividing by $I\exp{(i\tilde\omega\Delta t\,n)}$ gives

!bt
\begin{align}
q\exp{(i\tilde\omega\Delta t)} &= q - \omega^2 \Delta t,
label{vib:exer:EulerCromer:analysis:equ} \\
\exp{(i\tilde\omega\Delta t)} &= 1 + \Delta t\, q\exp{(i\tilde\omega\Delta t)}
label{vib:exer:EulerCromer:analysis:eqv}\tp
\end{align}
!et
Solving (ref{vib:exer:EulerCromer:analysis:eqv}) with respect to $q$ gives

!bt
\[ q = \frac{1}{\Delta t}\left( 1 - \exp{(i\tilde\omega\Delta t)} \right)\tp\]
!et
Inserting this expression for $q$ in (ref{vib:exer:EulerCromer:analysis:equ})
results in

!bt
\[ \exp{(i\tilde\omega\Delta t)} + \exp{(-i\tilde\omega\Delta t)} -2
= - \omega^2\Delta t^2\tp\]
!et
Using the relation
$\exp{(i\tilde\omega(\Delta t))} + \exp{(i\tilde\omega(-\Delta t))} - 2
= -4\sin^2(\frac{\tilde\omega\Delta t}{2})$ gives

!bt
\[ -4\sin^2(\frac{\tilde\omega\Delta t}{2}) = - \omega^2\Delta t^2,\]
!et
or after dividing by 4,

!bt
\[
\sin^2(\frac{\tilde\omega\Delta t}{2}) = \left(\frac{1}{2}\omega\Delta t\right)^2,\]
!et
which is the same equation for $\tilde\omega$ as found in
Section ref{vib:ode1:analysis}, such that $\tilde\omega$ is the
same. The accuracy, stability, and formula for the exact discrete solution
are then all the same as derived in Section ref{vib:ode1:analysis}.
#This proves that the solution of the Euler-Cromer scheme
#coincides
!esol

===== Exercise: Use the forward-backward scheme with quadratic damping =====
label{vib:exer:quad:damping:fwbw}
file=vib_gen_bwdamping

We consider the generalized model with quadratic damping, expressed
as a system of two first-order equations as in Section ref{vib:ode2:staggered}:

!bt
\begin{align*}
u^{\prime} &= v,\\
v' &= \frac{1}{m}\left( F(t) - \beta |v|v - s(u)\right)\tp
\end{align*}
!et
However, contrary to what is done in Section ref{vib:ode2:staggered},
we want to apply the idea of a forward-backward discretization:
$u$ is marched forward by a one-sided Forward Euler scheme applied
to the first equation, and
thereafter $v$ can be marched forward by a Backward Euler scheme in the
second
% if BOOK == "book":
equation, see in Section ref{vib:model2x2:EulerCromer}.
% else:
equation.
% endif
Express the idea in operator notation and write out the
scheme. Unfortunately, the backward difference for the $v$ equation
creates a nonlinearity $|v^{n+1}|v^{n+1}$.  To linearize this
nonlinearity, use the known value $v^n$ inside the absolute value
factor, i.e., $|v^{n+1}|v^{n+1}\approx |v^n|v^{n+1}$.  Show that the
resulting scheme is equivalent to the one in Section
ref{vib:ode2:staggered} for some time level $n\geq 1$.

What we learn from this exercise is that the first-order differences
and the linearization trick play together in ``the right way'' such that
the scheme is as good as when we (in Section ref{vib:ode2:staggered})
carefully apply centered differences and a geometric mean on a
staggered mesh to achieve second-order accuracy.
% if BOOK == "book":
There is a
difference in the handling of the initial conditions, though, as
explained at the end of Section ref{vib:model2x2:EulerCromer}.
% endif
