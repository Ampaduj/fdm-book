[hpl: Here is a todo list.]

 * There are few index entries, see the ``wave equation'' index entries and
   how many sub-entries we have there...
 * Check if the material on diffusion equation with radial symmetry is
   okay.
 * Implement a diffusion equation with axi-symmetry such we can solve
   pulsating flow in a circular blood vessel, see Exercise ref{diffu:exer:bloodflow}.

idx{diffusion equation!1D}
idx{heat equation}
idx{diffusion coefficient}
idx{diffusion equation!diffusion coefficient}

The famous *diffusion equation*, also known as the *heat equation*,
reads

!bt
\[ \frac{\partial u}{\partial t} =
\dfc \frac{\partial^2 u}{\partial x^2},
\]
!et
where $u(x,t)$ is the unknown function to be solved for, $x$ is a coordinate
in space, and $t$ is time. The coefficient $\dfc$ is the *diffusion
coefficient* and determines how fast $u$ changes in time. A quick
short form for the diffusion equation is $u_t = \dfc u_{xx}$.

Compared to the wave equation, $u_{tt}=c^2u_{xx}$, which looks very similar,
the diffusion equation features solutions that are very different from
those of the wave equation. Also, the diffusion equation
makes quite different demands to the numerical
methods.

idx{diffusion equation!stationary solution}
idx{stationary solution}
idx{Laplace equation}

Typical diffusion problems may experience rapid change in the very
beginning, but then the evolution of $u$ becomes slower and slower.
The solution is usually very smooth, and after some time, one cannot
recognize the initial shape of $u$. This is in sharp contrast to
solutions of the wave equation where the initial shape is preserved in
homogeneous media -- the solution is then basically a moving initial
condition. The standard wave equation $u_{tt}=c^2u_{xx}$ has solutions
that propagates with speed $c$ forever, without changing shape, while
the diffusion equation converges to a *stationary solution* $\bar
u(x)$ as $t\rightarrow\infty$. In this limit, $u_t=0$, and $\bar u$ is
governed by $\bar u''(x)=0$.  This stationary limit of the diffusion
equation is called the *Laplace* equation and arises in a very wide
range of applications throughout the sciences.

It is possible to solve for $u(x,t)$ using an explicit scheme, as we
do in Section ref{diffu:pde1:FEsec}, but the time step restrictions
soon become much less favorable than for an explicit scheme applied to
the wave equation. And of more importance, since the solution $u$ of
the diffusion equation is very smooth and changes slowly, small time
steps are not convenient and not required by accuracy as the diffusion
process converges to a stationary state. Therefore, implicit schemes
(as described in Section ref{diffu:pde1:implicit}) are popular, but
these require solutions of systems of algebraic equations. We shall
use ready-made software for this purpose, but also program some simple
iterative methods.


======= An explicit method for the 1D diffusion equation =======
label{diffu:pde1:FEsec}

Explicit finite difference methods for the wave equation $u_{tt}=c^2u_{xx}$
can be used, with small modifications, for solving $u_t = \dfc u_{xx}$
as well.
% if BOOK == "book":
The exposition below assumes that the reader is familiar with the
basic ideas of discretization and implementation of wave
equations from Chapter ref{ch:wave}. Readers not familiar with the
Forward Euler, Backward Euler, and Crank-Nicolson (or centered or
midpoint) discretization methods in time should consult, e.g.,
ref[Section ref{decay:basics}][ in cite{Langtangen_decay}][the
section "Finite difference methods": "http://hplgit.github.io/decay-book/doc/pub/book/sphinx/._book002.html#finite-difference-methods" in cite{Langtangen_decay}].
% endif

===== The initial-boundary value problem for 1D diffusion =====

To obtain a unique solution of the diffusion equation, or equivalently,
to apply numerical methods, we need initial and boundary conditions.
The diffusion equation goes with one initial condition $u(x,0)=I(x)$, where
$I$ is a prescribed function. One boundary condition is required at
each point on the boundary, which in 1D means that $u$ must be known,
$u_x$ must be known, or some combination of them.

idx{diffusion equation! 1D, explicit scheme}
idx{diffusion equation! 1D, initial boundary value problem}
idx{diffusion equation! 1D, initial condition}
idx{diffusion equation! 1D, boundary condition}

We shall start
with the simplest boundary condition: $u=0$. The complete
initial-boundary value diffusion problem in one
space dimension can then be specified as

# #if FORMAT in ("latex", "pdflatex")
!bt
\begin{alignat}{3}
\frac{\partial u}{\partial t} &=
\dfc \frac{\partial^2 u}{\partial x^2} + f, \quad & x\in (0,L),\ t\in (0,T]
label{diffu:pde1}\\
u(x,0) &= I(x), \quad & x\in [0,L]
label{diffu:pde1:ic:u}\\
u(0,t) & = 0, \quad & t>0,
label{diffu:pde1:bc:0}\\
u(L,t) & = 0, \quad & t>0
\tp
label{diffu:pde1:bc:L}
\end{alignat}
!et
# #else
!bt
\begin{align}
\frac{\partial u}{\partial t} &=
\dfc \frac{\partial^2 u}{\partial x^2} + f, \quad x\in (0,L),\ t\in (0,T]
label{diffu:pde1}\\
u(x,0) &= I(x), \quad  x\in [0,L]
label{diffu:pde1:ic:u}\\
u(0,t) & = 0, \quad  t>0,
label{diffu:pde1:bc:0}\\
u(L,t) & = 0, \quad  t>0\tp
label{diffu:pde1:bc:L}
\end{align}
!et
# #endif
With only a first-order derivative in time,
only one *initial condition* is needed, while the second-order
derivative in space leads to a demand for two *boundary conditions*.
We have added a source term $f=f(x,t)$, which is
convenient when testing implementations.

idx{diffusion equation!source term}

Diffusion equations like (ref{diffu:pde1}) have a wide range of
applications throughout physical, biological, and financial sciences.
One of the most common applications is propagation of heat, where
$u(x,t)$ represents the temperature of some substance at point $x$ and
time $t$. Other applications are listed in Section ref{diffu:app}.


===== Forward Euler scheme =====
label{diffu:pde1:FE}
idx{explicit discretization methods}
idx{diffusion equation! 1D, Forward Euler scheme}
idx{domain}
idx{mesh points}
idx{mesh function}
idx{forward difference approximation}
idx{central difference approximation}
idx{diffusion equation! 1D, discrete equations}
idx{diffusion equation! 1D, Fourier number}
idx{diffusion equation! 1D, mesh Fourier number}
idx{dimensionless number}

The first step in the discretization procedure is to replace the
domain $[0,L]\times [0,T]$ by a set of mesh points. Here we apply
equally spaced mesh points

!bt
\begin{equation*} x_i=i\Delta x,\quad i=0,\ldots,N_x,\end{equation*}
!et
and

!bt
\begin{equation*} t_n=n\Delta t,\quad n=0,\ldots,N_t \tp  \end{equation*}
!et
Moreover, $u^n_i$ denotes the mesh function that
approximates $u(x_i,t_n)$ for $i=0,\ldots,N_x$ and $n=0,\ldots,N_t$.
Requiring the PDE (ref{diffu:pde1}) to be fulfilled at a mesh point $(x_i,t_n)$
leads to the equation

!bt
\begin{equation}
\frac{\partial}{\partial t} u(x_i, t_n) =
\dfc\frac{\partial^2}{\partial x^2} u(x_i, t_n) + f(x_i,t_n),
label{diffu:pde1:step2}
\end{equation}
!et
The next step is to replace the derivatives by finite difference approximations.
The computationally simplest method arises from
using a forward difference in time and a central difference in
space:

!bt
\begin{equation}
[D_t^+ u = \dfc D_xD_x u + f]^n_i \tp
label{diffu:pde1:step3a}
\end{equation}
!et
Written out,

!bt
\begin{equation}
\frac{u^{n+1}_i-u^n_i}{\Delta t} = \dfc \frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2} + f_i^n\tp
label{diffu:pde1:step3b}
\end{equation}
!et
We have turned the PDE into algebraic equations, also often called
discrete equations. The key property of the equations is that they
are algebraic, which makes them easy to solve.
As usual, we anticipate that $u^n_i$ is already computed such that
$u^{n+1}_i$ is the only unknown in (ref{diffu:pde1:step3b}).
Solving with respect to this unknown is easy:

!bt
\begin{equation}
u^{n+1}_i = u^n_i + F\left(
u^{n}_{i+1} - 2u^n_i + u^n_{i-1}\right) + \Delta t f_i^n,
label{diffu:pde1:step4}
\end{equation}
!et
where we have introduced the *mesh Fourier number*:

!bt
\begin{equation}
F = \dfc\frac{\Delta t}{\Delta x^2}\tp
\end{equation}
!et

!bnotice $F$ is the key parameter in the discrete diffusion equation
Note that $F$ is a *dimensionless* number that lumps the key physical
parameter in the problem, $\dfc$, and the discretization parameters
$\Delta x$ and $\Delta t$ into a single parameter. Properties
of the numerical method are critically dependent upon the value of
$F$ (see Section ref{diffu:pde1:analysis} for details).
!enotice

The computational algorithm then becomes

  o compute $u^0_i=I(x_i)$for $i=0,\ldots,N_x$
  o for $n=0,1,\ldots,N_t$:
    o apply (ref{diffu:pde1:step4}) for all the internal
      spatial points $i=1,\ldots,N_x-1$
    o set the boundary values
      $u^{n+1}_i=0$ for $i=0$ and $i=N_x$

The algorithm is compactly and fully specified in Python:

!bc pycod
import numpy as np
x = np.linspace(0, L, Nx+1)    # mesh points in space
dx = x[1] - x[0]
t = np.linspace(0, T, Nt+1)    # mesh points in time
dt = t[1] - t[0]
F = a*dt/dx**2
u   = np.zeros(Nx+1)           # unknown u at new time level
u_n = np.zeros(Nx+1)           # u at the previous time level

# Set initial condition u(x,0) = I(x)
for i in range(0, Nx+1):
    u_n[i] = I(x[i])

for n in range(0, Nt):
    # Compute u at inner mesh points
    for i in range(1, Nx):
        u[i] = u_n[i] + F*(u_n[i-1] - 2*u_n[i] + u_n[i+1]) + \
	       dt*f(x[i], t[n])

    # Insert boundary conditions
    u[0] = 0;  u[Nx] = 0

    # Update u_n before next step
    u_n[:]= u
!ec
Note that we use `a` for $\dfc$ in the code, motivated by easy visual
mapping between the variable name and the mathematical symbol in formulas.

We need to state already now that the shown algorithm does not
produce meaningful results unless $F\leq 1/2$. Why is explained in
Section ref{diffu:pde1:analysis}.

===== Implementation =====
label{diffu:pde1:FE:code}
idx{diffusion equation! 1D, implementation (FE)}

The file "`diffu1D_u0.py`": "${src_diffu}/diffu1D_u0.py"
contains a complete function `solver_FE_simple`
for solving the 1D diffusion equation with $u=0$ on the boundary
as specified in the algorithm above:

@@@CODE src-diffu/diffu1D_u0.py fromto: import numpy@def solver_FE\(

A faster version, based on vectorization of the finite difference
scheme, is available in the function `solver_FE`.
The vectorized version replaces the explicit loop

!bc pycod
for i in range(1, Nx):
    u[i] = u_n[i] + F*(u_n[i-1] - 2*u_n[i] + u_n[i+1]) \
           + dt*f(x[i], t[n])
!ec
by arithmetics on displaced slices of the `u` array:

!bc pycod
u[1:Nx] = u_n[1:Nx] + F*(u_n[0:Nx-1] - 2*u_n[1:Nx] + u_n[2:Nx+1]) \
          + dt*f(x[1:Nx], t[n])
# or
u[1:-1] = u_n[1:-1] + F*(u_n[0:-2] - 2*u_n[1:-1] + u_n[2:]) \
          + dt*f(x[1:-1], t[n])
!ec
For example,
the vectorized version runs 70 times faster than the scalar version
in a case with 100 time steps and a spatial mesh of $10^5$ cells.

The `solver_FE` function also features a callback function such that the
user can process the solution at each time level. The callback
function looks like `user_action(u, x, t, n)`, where `u` is the array
containing the solution at time level `n`, `x` holds all the
spatial mesh points, while `t` holds all the temporal mesh points.
Apart from the vectorized loop over the spatial mesh points, the
callback function, and a bit more complicated setting of the source
`f` it is not specified (`None`), the `solver_FE` function is identical to
`solver_FE_simple` above:

@@@CODE src-diffu/diffu1D_u0.py fromto: def solver_FE\(@def solver_BE_simple

===== Verification =====
label{diffu:pde1:FE:verify}
idx{diffusion equation! 1D, verification (FE)}

=== Exact solution of discrete equations ===
label{diffu:pde1:FE:verify:exact}

Before thinking about running the functions in the previous section,
we need to construct a suitable test example for verification. It
appears that a manufactured solution that is linear in time and at
most quadratic in space fulfills the Forward Euler scheme
exactly. With the restriction that $u=0$ for $x=0,L$, we can try the
solution

!bt
\[ u(x,t) = 5tx(L-x)\tp\]
!et
Inserted in the PDE, it requires a source term

!bt
\[ f(x,t) = 10\dfc t + 5x(L-x)\tp\]
!et
% if BOOK == 'book':
With the formulas from Appendix ref{sec:form:fdtn} we can easily check
% else:
Let us check
% endif
that the manufactured `u` fulfills the scheme:

!bt
\begin{align*}
\lbrack D_t^+ u = \dfc D_x D_x u + f\rbrack^n_i &=
\lbrack 5x(L-x)D_t^+ t  = 5 t\dfc D_x D_x (xL-x^2) +\\
&\quad\quad 10\dfc t + 5x(L-x)\rbrack^n_i\\
&=
\lbrack 5x(L-x)  = 5 t\dfc (-2) + 10\dfc t + 5x(L-x) \rbrack^n_i\tp
\end{align*}
!et

The computation of the source term, given any $u$,
is easily automated with `sympy`:

!bc pycod
import sympy as sym
x, t, a, L = sym.symbols('x t a L')
u = x*(L-x)*5*t

def pde(u):
    return sym.diff(u, t) - a*sym.diff(u, x, x)

f = sym.simplify(pde(u))
!ec
Now we can choose any expression for `u` and automatically
get the suitable source term `f`. However, the manufactured solution
`u` will in general
not be exactly reproduced by the scheme: only constant and linear
functions are differentiated correctly by a forward difference, while only
constant, linear, and quadratic functions are differentiated exactly by
a $[D_xD_x u]^n_i$ difference.

The numerical code will need to access the `u` and `f` above
as Python functions. The exact solution is wanted as a Python
function `u_exact(x, t)`, while the source term is wanted as
`f(x, t)`. The parameters `a` and `L` in `u` and `f` above
are symbols and must be replaced by `float` objects in a Python
function. This can be done by redefining `a` and `L` as
`float` objects and performing substitutions of symbols by
numbers in `u` and `f`. The appropriate code looks like this:

!bc pycod
a = 0.5
L = 1.5
u_exact = sym.lambdify(
    [x, t], u.subs('L', L).subs('a', a), modules='numpy')
f = sym.lambdify(
    [x, t], f.subs('L', L).subs('a', a), modules='numpy')
I = lambda x: u_exact(x, 0)
!ec
Here we also make a function `I` for the initial condition.

The idea now is that our manufactured solution should be
exactly reproduced by the code (to machine precision).
For this purpose we make a test function for comparing
the exact and numerical solutions at the end of the
time interval:

!bc pycod
def test_solver_FE():
    # Define u_exact, f, I as explained above

    dx = L/3  # 3 cells
    F = 0.5
    dt = F*dx**2

    u, x, t, cpu = solver_FE_simple(
        I=I, a=a, f=f, L=L, dt=dt, F=F, T=2)
    u_e = u_exact(x, t[-1])
    diff = abs(u_e - u).max()
    tol = 1E-14
    assert diff < tol, 'max diff solver_FE_simple: %g' % diff

    u, x, t, cpu = solver_FE(
        I=I, a=a, f=f, L=L, dt=dt, F=F, T=2,
        user_action=None, version='scalar')
    u_e = u_exact(x, t[-1])
    diff = abs(u_e - u).max()
    tol = 1E-14
    assert diff < tol, 'max diff solver_FE, scalar: %g' % diff

    u, x, t, cpu = solver_FE(
        I=I, a=a, f=f, L=L, dt=dt, F=F, T=2,
        user_action=None, version='vectorized')
    u_e = u_exact(x, t[-1])
    diff = abs(u_e - u).max()
    tol = 1E-14
    assert diff < tol, 'max diff solver_FE, vectorized: %g' % diff
!ec

!bnotice The critical value $F=0.5$
We emphasize that the value `F=0.5` is critical: the tests above
will fail if `F` has a larger value. This is because the Forward
Euler scheme is unstable for $F>1/2$.

The reader may wonder if
$F=1/2$ is safe or if $F<1/2$ should be required. Experiments show
that $F=1/2$ works fine for $u_t=\dfc u_{xx}$, so
there is no accumulation of rounding
errors in this case and hence no need to introduce any safety factor
to keep $F$ away from the limiting value 0.5.
!enotice


=== Checking convergence rates ===
label{diffu:pde1:FE:verify:convrates}

If our chosen exact solution does not satisfy the discrete equations
exactly, we are left with checking the convergence rates, just as we did
previously for the wave equation. However, with the Euler scheme here,
we have different accuracies in time and space, since we use a second
order approximation to the spatial derivative and a first order approximation
to the time derivative. Thus, we must expect different convergence rates in
time and space. For the numerical error,

!bt
\[ E = C_t\Delta t^r + C_x\Delta x^p,\]
!et
we should get convergence rates $r=1$ and $p=2$ ($C_t$ and $C_x$ are unknown constants).
As previously, we simplify matters by introducing a single discretization parameter.
We introduce

!bt
\[ h = \Delta x^p,\quad h = K^{-1}\Delta t,\]
!et
where $K$ is a constant. The error formula then becomes

!bt
\[ E = C_t K^rh^r + C_xh^r = \tilde C h^r,\quad \tilde C = C_tK^r + C_x\tp\]
!et
where the computed rate $r$ should approach 1 with increasing resolution.
It is tempting to choose $K=1$, but for the Forward Euler method,
stability requires $\Delta t = hK \leq h/(4\dfc)$, so $K\leq 1/(4\dfc)$.

The alternative error measures are as outlined for the wave equation and
convergence rate computations may follow what was described previously in
Section ref{wave:pde2:fd:MMS}.


===== Numerical experiments =====
label{diffu:pde1:FE:experiments}
idx{diffusion equation! 1D, numerical experiments}

When a test function like the one above runs silently without errors,
we have some evidence for a correct implementation of the numerical
method.  The next step is to do some experiments with more interesting
solutions.

We target a scaled diffusion problem where $x/L$ is a new spatial
coordinate and $\dfc t/L^2$ is a new time coordinate. The source term
$f$ is omitted, and $u$ is scaled by $\max_{x\in [0,L]}|I(x)|$ (see
ref[Section ref{sec:scale:diffu}][ in
cite{Langtangen_scaling}]["Scaling of the diffusion equation":
"http://hplgit.github.io/scaling-book/doc/pub/book/html/._scaling-book008.html#sec:scale:diffu" cite{Langtangen_scaling}] for details).
The governing PDE is then

!bt
\[ \frac{\partial u}{\partial t} = \frac{\partial^2 u}{\partial x^2},\]
!et
in the spatial domain $[0,L]$, with boundary conditions $u(0)=u(1)=0$.
Two initial conditions will be tested: a discontinuous plug,

!bt
\[ I(x) = \left\lbrace\begin{array}{ll}
0, & |x-L/2| > 0.1\\
1, & \hbox{otherwise}
\end{array}\right.\]
!et
and a smooth Gaussian function,

!bt
\[ I(x) = e^{-\frac{1}{2\sigma^2}(x-L/2)^2}\tp\]
!et
The functions `plug` and `gaussian` in "`diffu1D_u0.py`":
"${src_diffu}/diffu1D_u0.py" run the two cases,
respectively:

@@@CODE src-diffu/diffu1D_u0.py fromto: def plug@def expsin
These functions make use of the function `viz` for running the
solver and visualizing the solution using a callback function
with plotting:

@@@CODE src-diffu/diffu1D_u0.py fromto: def viz@def plug
Notice that this `viz` function stores all the solutions in a
list `solutions` in the callback function. Modern computers have
hardly any problem with storing a lot of such solutions for moderate
values of $N_x$ in 1D problems, but for 2D and 3D problems, this
technique cannot be used and solutions must be stored in files.

[hpl: Better to show the scalable file solution here?]

Our experiments employ a time step $\Delta t = 0.0002$ and
simulate for $t\in [0,0.1]$. First we try the highest value of
$F$: $F=0.5$. This resolution corresponds to
$N_x=50$. A possible terminal command is

!bc sys
Terminal> python -c 'from diffu1D_u0 import gaussian
          gaussian("solver_FE", F=0.5, dt=0.0002)'
!ec

The $u(x,t)$ curve as a function of $x$ is shown in Figure
ref{diffu:pde1:FE:fig:F=0.5} at four time levels.

MOVIE: [mov-diffu/diffu1D_u0_FE_plug/movie.ogg]

# "movie": "${doc_notes}/pub/diffu/html/mov-diffu/diffu1D_u0_FE_plug/movie.ogg"
# Does not work:
#http://tinyurl.com/pu5uyfn/pub/diffu/html/mov-diffu/diffu1D_u0_FE_plug/movie.ogg
# Works:
#https://raw.githubusercontent.com/hplgit/fdm-book/master/doc/.src/book/mov-diffu/diffu1D_u0_FE_plug/movie.ogg

We see that the curves have saw-tooth waves in the beginning of the
simulation. This non-physical noise is smoothed out with time, but
solutions of the diffusion equations are known to be smooth, and
this numerical solution is definitely not smooth.
Lowering $F$ helps: $F\leq 0.25$ gives a smooth solution, see
% if FORMAT == "pdflatex":
Figure ref{diffu:pde1:FE:fig:F=0.25} (and a
"movie": "${docraw}/mov-diffu/diffu1D_u0_FE_plug_F025/movie.ogg").
% else:
Figure ref{diffu:pde1:FE:fig:F=0.25}.

MOVIE: [mov-diffu/diffu1D_u0_FE_plug_F025/movie.ogg]
% endif

Increasing $F$ slightly beyond the limit 0.5, to $F=0.51$,
gives growing, non-physical instabilities,
as seen in Figure ref{diffu:pde1:FE:fig:F=0.51}.

FIGURE: [fig-diffu/plug_FE_F05, width=800 frac=1] Forward Euler scheme for $F=0.5$. label{diffu:pde1:FE:fig:F=0.5}

FIGURE: [fig-diffu/plug_FE_F025, width=800 frac=1] Forward Euler scheme for $F=0.25$. label{diffu:pde1:FE:fig:F=0.25}

FIGURE: [fig-diffu/plug_FE_F051, width=800 frac=1] Forward Euler scheme for $F=0.51$. label{diffu:pde1:FE:fig:F=0.51}


Instead of a discontinuous initial condition we now try the smooth
Gaussian function for $I(x)$. A simulation for $F=0.5$
is shown in Figure ref{diffu:pde1:FE:fig:gauss:F=0.5}. Now the numerical solution
is smooth for all times, and this is true for any $F\leq 0.5$.

% if FORMAT != "pdflatex":
MOVIE: [mov-diffu/diffu1D_u0_FE_gaussian1/movie.ogg]
% endif

FIGURE: [fig-diffu/gaussian_FE_F05, width=800 frac=1] Forward Euler scheme for $F=0.5$. label{diffu:pde1:FE:fig:gauss:F=0.5}

Experiments with these two choices of $I(x)$ reveal some
important observations:

 * The Forward Euler scheme leads to growing solutions if $F>\half$.
 * $I(x)$ as a discontinuous plug leads to a saw tooth-like noise
   for $F=\half$, which is absent for $F\leq\frac{1}{4}$.
 * The smooth Gaussian initial function leads to a smooth solution
   for all relevant $F$ values ($F\leq \half$).


======= Implicit methods for the 1D diffusion equation =======
label{diffu:pde1:implicit}
idx{diffusion equation! 1D, implicit schemes}

Simulations with the Forward Euler scheme shows that the time step
restriction, $F\leq\half$, which means $\Delta t \leq \Delta x^2/(2\dfc)$,
may be relevant in the beginning of the diffusion process, when the
solution changes quite fast, but as time increases, the process slows
down, and a small $\Delta t$ may be inconvenient. By using
*implicit schemes*, which lead to coupled systems of linear equations
to be solved at each time level, any size of $\Delta t$ is possible
(but the accuracy decreases with increasing $\Delta t$).
The Backward Euler scheme, derived and implemented below, is the
simplest implicit scheme for the diffusion equation.

===== Backward Euler scheme =====
label{diffu:pde1:BE}

We now apply a backward difference in time in (ref{diffu:pde1:step2}),
but the same central difference in space:

!bt
\begin{equation}
[D_t^- u = D_xD_x u + f]^n_i,
label{diffu:pde1:step3aBE}
\end{equation}
!et
which written out reads

!bt
\begin{equation}
\frac{u^{n}_i-u^{n-1}_i}{\Delta t} = \dfc\frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2} + f_i^n\tp
label{diffu:pde1:step3bBE}
\end{equation}
!et
Now we assume $u^{n-1}_i$ is already computed, but all quantities at the ``new''
time level $n$ are unknown. This time it is not possible to solve
with respect to $u_i^{n}$ because this value couples to its neighbors
in space, $u^n_{i-1}$ and $u^n_{i+1}$, which are also unknown.
Let us examine this fact for the case when $N_x=3$. Equation (ref{diffu:pde1:step3bBE}) written for $i=1,\ldots,Nx-1= 1,2$ becomes

!bt
\begin{align}
\frac{u^{n}_1-u^{n-1}_1}{\Delta t} &= \dfc\frac{u^{n}_{2} - 2u^n_1 + u^n_{0}}{\Delta x^2} + f_1^n\\
\frac{u^{n}_2-u^{n-1}_2}{\Delta t} &= \dfc\frac{u^{n}_{3} - 2u^n_2 + u^n_{1}}{\Delta x^2} + f_2^n
\end{align}
!et
The boundary values $u^n_0$ and $u^n_3$ are known as zero. Collecting the
unknown new values $u^n_1$ and $u^n_2$ on the left-hand side and multiplying
by $\Delta t$ gives

!bt
\begin{align}
\left(1+  2F\right) u^{n}_1 - F u^{n}_{2}    &= u^{n-1}_1 + \Delta t f_1^n,\\
- F u^{n}_{1} + \left(1+  2F\right) u^{n}_2  &= u^{n-1}_2 + \Delta t f_2^n\tp
\end{align}
!et
This is a coupled $2\times 2$ system of algebraic equations for
the unknowns $u^n_1$ and $u^n_2$. The equivalent matrix form is

!bt
\[ \left(\begin{array}{cc}
1+  2F &   - F\\
- F    & 1+  2F
\end{array}\right)
\left(\begin{array}{c}
u^{n}_1\\
u^{n}_2
\end{array}\right)
=
\left(\begin{array}{c}
u^{n-1}_1 + \Delta t f_1^n\\
u^{n-1}_2 + \Delta t f_2^n
\end{array}\right)
\]
!et

!bnotice Implicit vs. explicit methods
Discretization methods that lead to a coupled system of equations
for the unknown function at a new time level are said to be
*implicit methods*.
The counterpart, *explicit methods*, refers to discretization
methods where there is a simple explicit formula for the values of
the unknown function at each of the spatial mesh points at the new
time level. From an implementational point of view, implicit methods
are more comprehensive to code since they require
the solution of coupled equations, i.e., a matrix system, at each time level.
!enotice

In the general case, (ref{diffu:pde1:step3bBE}) gives rise to
a coupled $(N_x-1)\times (N_x-1)$ system of algebraic equations for
all the unknown $u^n_i$ at the interior spatial points $i=1,\ldots,N_x-1$.
Collecting the unknowns on the left-hand side,
(ref{diffu:pde1:step3bBE}) can be written

!bt
\begin{equation}
- F u^n_{i-1} + \left(1+  2F \right) u^{n}_i - F u^n_{i+1} =
u_{i-1}^{n-1},
label{diffu:pde1:step4BE}
\end{equation}
!et
for $i=1,\ldots,N_x-1$.
One can either view these equations as a system for where the
$u^{n}_i$ values at the internal mesh points, $i=1,\ldots,N_x-1$, are
unknown, or we may append the boundary values $u^n_0$ and $u^n_{N_x}$
to the system. In the latter case, all $u^n_i$ for $i=0,\ldots,N_x$
are considered unknown, and we must add the boundary equations to
the $N_x-1$ equations in (ref{diffu:pde1:step4BE}):

!bt
\begin{align}
u_0^n &= 0,label{diffu:pde1:step4BE:BC:0}\\
u_{N_x}^n &= 0\tp
label{diffu:pde1:step4BE:BC:L}
\end{align}
!et

A coupled system of algebraic equations can be written on matrix form,
and this is important if we want to call up ready-made software for
solving the system.  The equations (ref{diffu:pde1:step4BE})
and (ref{diffu:pde1:step4BE:BC:0})--(ref{diffu:pde1:step4BE:BC:L})
correspond to the matrix equation

!bt
\begin{equation*} AU = b\end{equation*}
!et
where $U=(u^n_0,\ldots,u^n_{N_x})$, and
the matrix $A$ has the following structure:

!bt
\begin{equation}
A =
\left(
\begin{array}{cccccccccc}
A_{0,0} & A_{0,1} & 0
&\cdots &
\cdots & \cdots & \cdots &
\cdots & 0 \\
A_{1,0} & A_{1,1} & A_{1,2} & \ddots &   & &  & &  \vdots \\
0 & A_{2,1} & A_{2,2} & A_{2,3} &
\ddots & &  &  & \vdots \\
\vdots & \ddots &  & \ddots & \ddots & 0 &  & & \vdots \\
\vdots &  & \ddots & \ddots & \ddots & \ddots & \ddots & & \vdots \\
\vdots & &  & 0 & A_{i,i-1} & A_{i,i} & A_{i,i+1} & \ddots & \vdots \\
\vdots & & &  & \ddots & \ddots & \ddots &\ddots  & 0 \\
\vdots & & & &  &\ddots  & \ddots &\ddots  & A_{N_x-1,N_x} \\
0 &\cdots & \cdots &\cdots & \cdots & \cdots  & 0 & A_{N_x,N_x-1} & A_{N_x,N_x}
\end{array}
\right)
label{diffu:pde1:matrix:sparsity}
\end{equation}
!et
The nonzero elements are given by

!bt
\begin{align}
A_{i,i-1} &= -F\\
A_{i,i} &= 1+ 2F\\
A_{i,i+1} &= -F
\end{align}
!et
in the equations for internal points, $i=1,\ldots,N_x-1$. The first and last
equation correspond to the boundary condition, where we know the solution,
and therefore we must have

!bt
\begin{align}
A_{0,0} &= 1,\\
A_{0,1} &= 0,\\
A_{N_x,N_x-1} &= 0,\\
A_{N_x,N_x} &= 1\tp
\end{align}
!et
The right-hand side $b$ is written as

!bt
\begin{equation}
b = \left(\begin{array}{c}
b_0\\
b_1\\
\vdots\\
b_i\\
\vdots\\
b_{N_x}
\end{array}\right)
\end{equation}
!et
with

!bt
\begin{align}
b_0 &= 0,\\
b_i &= u^{n-1}_i,\quad i=1,\ldots,N_x-1,\\
b_{N_x} &= 0 \tp  \end{align}
!et

We observe that the matrix $A$ contains quantities that do not change
in time. Therefore, $A$ can be formed once and for all before we enter
the recursive formulas for the time evolution.
The right-hand side $b$, however, must be updated at each time step.
This leads to the following computational algorithm, here sketched
with Python code:

!bc pycod
x = np.linspace(0, L, Nx+1)   # mesh points in space
dx = x[1] - x[0]
t = np.linspace(0, T, N+1)    # mesh points in time
u   = np.zeros(Nx+1)          # unknown u at new time level
u_n = np.zeros(Nx+1)          # u at the previous time level

# Data structures for the linear system
A = np.zeros((Nx+1, Nx+1))
b = np.zeros(Nx+1)

for i in range(1, Nx):
    A[i,i-1] = -F
    A[i,i+1] = -F
    A[i,i] = 1 + 2*F
A[0,0] = A[Nx,Nx] = 1

# Set initial condition u(x,0) = I(x)
for i in range(0, Nx+1):
    u_n[i] = I(x[i])

import scipy.linalg

for n in range(0, Nt):
    # Compute b and solve linear system
    for i in range(1, Nx):
        b[i] = -u_n[i]
    b[0] = b[Nx] = 0
    u[:] = scipy.linalg.solve(A, b)

    # Update u_n before next step
    u_n[:] = u
!ec

Regarding verification, the same considerations apply as for the
Forward Euler method (Section ref{diffu:pde1:FE:verify}).

idx{diffusion equation! 1D, verification (BE)}


===== Sparse matrix implementation =====
label{diffu:pde1:impl:sparse}
idx{diffusion equation! 1D, tridiagonal matrix}

We have seen from (ref{diffu:pde1:matrix:sparsity}) that the matrix
$A$ is tridiagonal. The code segment above used a full, dense matrix
representation of $A$, which stores a lot of values we know are zero
beforehand, and worse, the solution algorithm computes with all these
zeros.  With $N_x+1$ unknowns, the work by the solution algorithm is
$\frac{1}{3} (N_x+1)^3$ and the storage requirements $(N_x+1)^2$. By
utilizing the fact that $A$ is tridiagonal and employing corresponding
software tools that work with the three diagonals, the work and
storage demands can be proportional to $N_x$ only.  This leads to a
dramatic improvement: with $N_x=200$, which is a realistic resolution,
the code runs about 40,000 times faster and reduces the storage to
just 1.5%! It is no doubt that we should take advantage of the fact
that $A$ is tridiagonal.

The key idea is to apply a data structure for a tridiagonal or sparse
matrix. The `scipy.sparse` package has relevant utilities. For
example, we can store only the nonzero diagonals of a matrix. The
package also has linear system solvers that operate on sparse matrix
data structures. The code below illustrates how we can store only the
main diagonal and the upper and lower diagonals.

!bc pycod
# Representation of sparse matrix and right-hand side
main  = np.zeros(Nx+1)
lower = np.zeros(Nx)
upper = np.zeros(Nx)
b     = np.zeros(Nx+1)

# Precompute sparse matrix
main[:] = 1 + 2*F
lower[:] = -F
upper[:] = -F
# Insert boundary conditions
main[0] = 1
main[Nx] = 1

A = scipy.sparse.diags(
    diagonals=[main, lower, upper],
    offsets=[0, -1, 1], shape=(Nx+1, Nx+1),
    format='csr')
print A.todense()  # Check that A is correct

# Set initial condition
for i in range(0,Nx+1):
    u_n[i] = I(x[i])

for n in range(0, Nt):
    b = u_n
    b[0] = b[-1] = 0.0  # boundary conditions
    u[:] = scipy.sparse.linalg.spsolve(A, b)
    u_n[:] = u
!ec
The `scipy.sparse.linalg.spsolve` function utilizes the sparse storage
structure of `A` and performs, in this case, a very efficient Gaussian
elimination solve.

The program "`diffu1D_u0.py`": "${src_diffu}/diffu1D_u0.py"
contains a function `solver_BE`, which implements the Backward Euler scheme
sketched above.
As mentioned in Section ref{diffu:pde1:FE},
the functions `plug` and `gaussian`
runs the case with $I(x)$ as a discontinuous plug or a smooth
Gaussian function. All experiments point to two characteristic
features of the Backward Euler scheme: 1) it is always stable, and
2) it always gives a smooth, decaying solution.

===== Crank-Nicolson scheme =====
label{diffu:pde1:CN}
idx{diffusion equation! 1D, Crank-Nicolson scheme}

The idea in the Crank-Nicolson scheme is to apply centered
differences in space and time, combined with an average in time.
We demand the PDE to be fulfilled at the spatial mesh points, but
midway between the points in the time mesh:

!bt
\[
\frac{\partial}{\partial t} u(x_i, t_{n+\half}) =
\dfc\frac{\partial^2}{\partial x^2}u(x_i, t_{n+\half}) + f(x_i,t_{n+\half}),
\]
!et
for $i=1,\ldots,N_x-1$ and $n=0,\ldots, N_t-1$.

With centered differences in space and time, we get

!bt
\[ [D_t u = \dfc D_xD_x u + f]^{n+\half}_i\tp\]
!et
On the right-hand side we get an expression

!bt
\[ \frac{1}{\Delta x^2}\left(u^{n+\half}_{i-1} - 2u^{n+\half}_i + u^{n+\half}_{i+1}\right) + f_i^{n+\half}\tp\]
!et
This expression is problematic since $u^{n+\half}_i$ is not one of
the unknowns we compute. A possibility is to replace $u^{n+\half}_i$
by an arithmetic average:

!bt
\[ u^{n+\half}_i\approx
\half\left(u^{n}_i +u^{n+1}_{i}\right)\tp
\]
!et
In the compact notation, we can use the arithmetic average
notation $\overline{u}^t$:

!bt
\[ [D_t u = \dfc D_xD_x \overline{u}^t + f]^{n+\half}_i\tp\]
!et
We can also use an average for $f_i^{n+\half}$:

!bt
\[ [D_t u = \dfc D_xD_x \overline{u}^t + \overline{f}^t]^{n+\half}_i\tp\]
!et

After writing out the differences and average, multiplying by $\Delta t$,
and collecting all unknown terms on the left-hand side, we get

!bt
\begin{align}
u^{n+1}_i - \half F(u^{n+1}_{i-1} - 2u^{n+1}_i + u^{n+1}_{i+1})
&= u^{n}_i + \half F(u^{n}_{i-1} - 2u^{n}_i + u^{n}_{i+1})\nonumber\\
&\qquad \half f_i^{n+1} + \half f_i^n\tp
\end{align}
!et

Also here, as in the Backward Euler scheme, the new unknowns
$u^{n+1}_{i-1}$, $u^{n+1}_{i}$, and $u^{n+1}_{i+1}$ are coupled
in a linear system $AU=b$, where $A$ has the same structure
as in (ref{diffu:pde1:matrix:sparsity}), but with slightly
different entries:

!bt
\begin{align}
A_{i,i-1} &= -\half F\\
A_{i,i} &= 1 + F\\
A_{i,i+1} &= -\half F
\end{align}
!et
in the equations for internal points, $i=1,\ldots,N_x-1$. The equations
for the boundary points correspond to

!bt
\begin{align}
A_{0,0} &= 1,\\
A_{0,1} &= 0,\\
A_{N_x,N_x-1} &= 0,\\
A_{N_x,N_x} &= 1\tp
\end{align}
!et
The right-hand side $b$ has entries


!bt
\begin{align}
b_0 &= 0,\\
b_i &= u^{n-1}_i + \half(f_i^n + f_i^{n+1}),\quad i=1,\ldots,N_x-1,\\
b_{N_x} &= 0 \tp  \end{align}
!et

When verifying some implementation of the Crank-Nicolson scheme by convergence rate testing,
one should note that the scheme is second order accurate in both space and time. The numerical
error then reads

!bt
\[ E = C_t\Delta t^r + C_x\Delta x^r,\]
!et
where $r=2$ ($C_t$ and $C_x$ are unknown constants, as before).
When introducing a single discretization parameter, we may now simply choose

!bt
\[ h = \Delta x = \Delta t,\]
!et
which gives
!bt
\[ E = C_th^r + C_xh^r = (C_t + C_x)h^r,\]
!et
where $r$ should approach 2 as resolution is increased in the convergence rate computations.

idx{diffusion equation! 1D, verification (CN)}


===== The unifying $\theta$ rule =====
label{diffu:pde1:theta}
idx{diffusion equation! 1D, theta rule}

For the equation

!bt
\[ \frac{\partial u}{\partial t} = G(u),\]
!et
where $G(u)$ is some
spatial differential operator, the $\theta$-rule
looks like

!bt
\[ \frac{u^{n+1}_i - u^n_i}{\Delta t} =
\theta G(u^{n+1}_i) + (1-\theta) G(u^{n}_i)\tp\]
!et
The important feature of this time discretization scheme is that
we can implement one formula and then generate a family of
well-known and widely used schemes:

 * $\theta=0$ gives the Forward Euler scheme in time
 * $\theta=1$ gives the Backward Euler scheme in time
 * $\theta=\half$ gives the Crank-Nicolson scheme in time

In the compact difference notation, we write the $\theta$ rule
as

!bt
\[ [D_t u = \dfc D_xD_x u]^{n+\theta}\tp\]
!et
We have that $t_{n+\theta} = \theta t_{n+1} + (1-\theta)t_n$.

Applied to the 1D diffusion problem, the $\theta$-rule gives

!bt
\begin{align*}
\frac{u^{n+1}_i-u^n_i}{\Delta t} &=
\dfc\left( \theta \frac{u^{n+1}_{i+1} - 2u^{n+1}_i + u^{n+1}_{i-1}}{\Delta x^2}
+ (1-\theta) \frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2}\right)\\
&\qquad + \theta f_i^{n+1} + (1-\theta)f_i^n
\tp
\end{align*}
!et
This scheme also leads to a matrix system with entries

!bt
\[ A_{i,i-1} = -F\theta,\quad A_{i,i} = 1+2F\theta\quad,
A_{i,i+1} = -F\theta,\]
!et
while right-hand side entry $b_i$ is

!bt
\[ b_i = u^n_{i} + F(1-\theta)
\frac{u^{n}_{i+1} - 2u^n_i + u^n_{i-1}}{\Delta x^2} +
\Delta t\theta f_i^{n+1} + \Delta t(1-\theta)f_i^n\tp
\]
!et
The corresponding entries for the boundary points are as in the Backward
Euler and Crank-Nicolson schemes listed earlier.

Note that convergence rate testing with implementations of the theta rule must
adjust the error expression according to which of the underlying schemes is actually being run.
That is, if $\theta=0$ (i.e., Forward Euler) or $\theta=1$ (i.e., Backward Euler), there should
be first order convergence, whereas with $\theta=0.5$ (i.e., Crank-Nicolson), one should get
second order convergence (as outlined in previous sections).


# #ifdef EXTRA
!bt
\begin{equation}
[D_t u = \dfc D_xD_x \overline{u}^{t,\theta}]^n_i
\end{equation}
!et
# #endif

===== Experiments =====
label{diffu:pde1:theta:experiments}

We can repeat the experiments from Section ref{diffu:pde1:FE:experiments}
to see if the Backward Euler or Crank-Nicolson schemes have problems
with sawtooth-like noise when starting with a discontinuous initial
condition. We can also verify that we can have $F>\half$,
which allows larger time steps than in the Forward Euler method.

FIGURE: [fig-diffu/plug_BE_F05, width=800 frac=1] Backward Euler scheme for $F=0.5$. label{diffu:pde1:BE:fig:F=0.5}

The Backward Euler scheme always produces smooth solutions for any $F$.
Figure ref{diffu:pde1:BE:fig:F=0.5} shows one example.
Note that the mathematical discontinuity at $t=0$ leads to a linear
variation on a mesh, but the approximation to a jump becomes better
as $N_x$ increases. In our simulation we specify $\Delta t$ and $F$,
and $N_x$ is set to $L/\sqrt{\dfc\Delta t/F}$. Since $N_x\sim\sqrt{F}$,
the discontinuity looks sharper in the Crank-Nicolson
simulations with larger $F$.

The Crank-Nicolson method produces smooth solutions for small $F$,
$F\leq\half$, but small noise gets more and more evident as $F$
increases. Figures ref{diffu:pde1:CN:fig:F=3} and ref{diffu:pde1:CN:fig:F=10}
demonstrate the effect for $F=3$ and $F=10$, respectively.
Section ref{diffu:pde1:analysis} explains why such noise occur.

FIGURE: [fig-diffu/plug_CN_F3, width=800 frac=1] Crank-Nicolson scheme for $F=3$. label{diffu:pde1:CN:fig:F=3}

FIGURE: [fig-diffu/plug_CN_F10, width=800 frac=1] Crank-Nicolson scheme for $F=10$. label{diffu:pde1:CN:fig:F=10}



===== The Laplace and Poisson equation =====

The Laplace equation, $\nabla^2 u = 0$, and the Poisson equation,
$-\nabla^2 u = f$, occur in numerous applications throughout science and
engineering. In 1D these equations read
$u''(x)=0$ and $-u''(x)=f(x)$, respectively.
We can solve 1D variants of the Laplace equations with the listed
software, because we can interpret $u_{xx}=0$ as the limiting solution
of $u_t = \dfc u_{xx}$ when $u$ reaches a steady state limit where
$u_t\rightarrow 0$.
Similarly, Poisson's equation $-u_{xx}=f$ arises from solving
$u_t = u_{xx} + f$ and letting $t\rightarrow\infty$ so $u_t\rightarrow 0$.

Technically in a program, we can simulate $t\rightarrow\infty$
by just taking one large time step:
$\Delta t\rightarrow\infty$. In the limit, the Backward Euler
scheme gives

!bt
\[ -\frac{u^{n+1}_{i+1} - 2u^{n+1}_i + u^{n+1}_{i-1}}{\Delta x^2} = f^{n+1}_i,\]
!et
which is nothing but the discretization $[-D_xD_x u = f]^{n+1}_i=0$ of
$-u_{xx}=f$.

The result above means that
the Backward Euler scheme can solve the limit equation directly and
hence produce a solution of the 1D Laplace equation.
With the Forward Euler scheme we must do the time stepping since $\Delta t >
\Delta x^2/\dfc$
is illegal and leads to instability.
We may interpret this time stepping
as solving the equation system from $-u_{xx}=f$ by iterating on a
pseudo time variable.

[hpl: Better to say the last sentence when we treat iterative methods.]

# #ifdef 2DO

===== Extensions =====

These extensions are performed exactly as for a wave equation as they
only affect the spatial derivatives (which are the same as in the
wave equation).

 * Variable coefficients
 * Neumann and Robin conditions
 * 2D and 3D

Future versions of this document will for completeness and
independence of the wave equation document feature info on the three
points. The Robin condition is new, but straightforward to handle:

!bt
\[ -\dfc\frac{\partial u}{\partial n} = h_T(u-U_s),\quad
[-\dfc D_x u = h_T(u-U_s)]^n_i
\]
!et

===== Implementation =====
label{diffu:pde1:impl}


===== Adaptive Time Stepping =====

Intuitive approach based on strategies from ODE decay equation and
a very discrete Fourier composition of analytical components.
What about $||u_t|| < \epsilon_L \Rightarrow \Delta t$ doubled,
$||u_t|| > \epsilon_U \Rightarrow \Delta t$ halved? Google...



===== Variable Diffusion Coefficient =====


!bt
\begin{equation}
\frac{\partial u}{\partial t} =
\frac{\partial}{\partial x}\left(
\dfc(x) \frac{\partial u}{\partial x}\right)
\end{equation}
!et

It is always very useful to have analytical solutions to PDEs.
For the variable coefficient diffusion equation this is difficult
to find unless we add a source term and apply the method of
manufactured solutions. In the  limit $t\rightarrow\infty$, however,
we can derive an analytical solution.
The limit problem for the stationary solution
$v(x) = \lim_{t\rightarrow \infty} u(x,t)$,
assuming $\partial u/\partial t\rightarrow 0$ in this limit, becomes

!bt
\begin{equation}
\frac{\partial}{\partial x}\left(
\dfc(x) \frac{\partial u}{\partial x}\right)
= 0,\quad v(0)=u_L,\ v(L)=u_R \tp  \end{equation}
!et
Integrating twice results in

!bt
\begin{equation*} v = C_2 + C_1\int_0^x \frac{1}{\dfc(\xi)} d\xi \tp  \end{equation*}
!et
The two integration constants $C_1$ and $C_2$ are determined from
the boundary conditions, and $v(x)$ becomes

!bt
\begin{equation}
v(x) = u_L + (u_R - u_L)
\frac{\int_0^x\frac{d\xi}{a(\xi)}}{\int_0^L\frac{d\xi}{a(\xi)}}
\end{equation}
!et

Evaluation of $v$ on a mesh with points $x_i$, $i=0,\ldots,N_x$,
can be performed using the Trapezoidal rule.
Defining $g(x) = \int_0^x (\dfc(\xi))^{-1}d\xi$, $g_j$ can be
computed as

!bt
\begin{equation}
g_i = \left\lbrace\begin{array}{ll}
\half \Delta x /\dfc_i, & i = 0,\\
g_{i-1} + \Delta x /\dfc_i, & 0 < i < N_x,\\
g_{i-1} + \half\Delta x /\dfc_i, & i = N_x \tp  \end{array}\right.
\end{equation}
!et
Then

!bt
\begin{equation}
v_i = u_L + (u_R - u_L)g_i/g_{N_x} \tp  \end{equation}
!et
The corresponding implementation can be written

!bc pycod
def u_exact_stationary(x, a, u_L, u_R):
    Nx = x.size - 1
    g = zeros(Nx+1)    # integral of 1/a from 0 to x
    dx = x[1] - x[0]   # assumed constant
    i = 0
    g[i] = 0.5*dx/a[i]
    for i in range(1, Nx):
        g[i] = g[i-1] + dx/a[i]
    i = Nx
    g[i] = g[i-1] + 0.5*dx/a[i]
    v = u_L + (u_R - u_L)*g/g[-1]
    return v
!ec



======= Two-Dimensional Diffusion =======
label{diffu:2D}

# #endif
