
# 5631 projects:
# Drop f_a, call py from f77
# Call py with cpdef f from Cython, but hardcode function name
# As above, but transfer function to Cython
# Instant
# test_quadratic for all
# Think of extensions: Neumann with modified stencil or ghost cells,
#   variable coefficients, damping, ...

# #ifdef PLAN
* Define some wave project, e.g., earthquake induced waves where
   a quite flat bottom has a discontinuity point/line and some part
   to the right lifts up suddenly and falls back?
 * Start with `wave1D_dn_vc.py` and `wave2D_u0.py`
 * Storing solutions with joblib, XDMF
   http://www.xdmf.org/index.php/Write_Xdmf
   http://www.xdmf.org/index.php/Xdmf3_Python_API
   OBS: both a post on the fenics list and here,
   URL: "http://fenicsproject.org/qa/6513/time-series-of-many-function-instances-in-a-single-file", suggests that paraview cannot view xdmf files will more
   than one field/function - should store in separate files...
   See the dolfin function that writes xdmf files before trying too much...
   FiPy applies "xdmf": "https://matforge.org/fipy/browser/fipy/fipy/io/xdmf/time.py?rev=517630187125d4aee390fd251ba42324b9aacce0"
   joblib vs "klepto": "http://stackoverflow.com/questions/28311141/decorators-for-selective-caching-memoization"
 * Problem and Solver classes
 * Profiling
 * Fortran, Cython, C, C++
 * Viz here? Movie making?
 * DrawFunction for drawing bottom and surface, build app for this :-)
 * Parampool with full pool ("menu")
# #endif

======= A 1D wave equation simulator =======

===== Mathematical model =====

idx{`wave1D_dn_vc.py`}

Let $u_t$, $u_{tt}$, $u_x$, $u_{xx}$ denote derivatives of $u$ with
respect to the subscript, i.e., $u_{tt}$ is a second-order time
derivative and $u_x$ is a first-order space derivative.  The
initial-boundary value problem implemented in the `wave1D_dn_vc.py`
code is

!bt
\begin{align}
u_{tt} &= (q(x)u_x)_x + f(x,t),\quad &x\in (0,L),\ t\in (0,T]
label{wave:pde2:software:ueq2}\\
u(x,0) &= I(x),\quad &x\in [0,L]\\
u_t(x,0) &= V(t),\quad &x\in [0,L]\\
u(0,t) &= U_0(t)\hbox{ or } u_x(0,t)=0,\quad &t\in (0,T]\\
u(L,t) &= U_L(t)\hbox{ or } u_x(L,t)=0,\quad &t\in (0,T]
label{wave:pde2:software:bcL2}
\end{align}
!et
We allow variable wave velocity $c^2(x)=q(x)$, and Dirichlet or homogeneous
Neumann conditions at the boundaries.


===== Numerical discretization =====

The PDE is discretized by second-order finite differences in
time and space, with arithmetic mean for the variable coefficient

!bt
\begin{equation}
[D_tD_t u = D_x\overline{q}^xD_x u + f]^n_i
\tp
\end{equation}
!et
The Neumann boundary conditions are discretized by

!bt
\[ [D_{2x}u]^n_i=0,\]
!et
at a boundary point $i$. The details of how the numerical scheme
is worked out are described in ref[Sections ref{wave:pde2:Neumann}
and ref{wave:pde2:var:c}][ in cite{Langtangen_deqbook_wave}][in
the document "Finite difference methods for wave motion":
"http://tinyurl.com/k3sdbuv/pub/wave"
cite{Langtangen_deqbook_wave}].

===== A solver function =====

The general initial-boundary value problem
(ref{wave:pde2:software:ueq2})-(ref{wave:pde2:software:bcL2})
solved by finite difference methods can be implemented as shown in
the following `solver` function (taken from the
file "`wave1D_dn_vc.py`": "${src_wave}/wave1D/wave_dn_vc.py").
This function builds on
simpler versions described in
ref[Sections ref{wave:pde1:impl}, ref{wave:pde1:impl:vec}
ref{wave:pde2:Neumann}, and ref{wave:pde2:var:c}][ in
cite{Langtangen_deqbook_wave}][in
the document "Finite difference methods for wave motion":
"http://tinyurl.com/k3sdbuv/pub/wave"
cite{Langtangen_deqbook_wave}].
There are several quite advanced
constructs that will be commented upon later.
The code is lengthy, but that is because we provide a lot of
flexibility with respect to input arguments,
boundary conditions, and optimization
(scalar versus vectorized loops).

@@@CODE src-wave/wave1D/wave1D_dn_vc.py def solver@def test_quadratic


======= Saving large arrays in files =======
label{softeng2:wave1D:filestorage}

Numerical simulations produce large arrays as results and the software
needs to store these arrays on disk. Several methods are available
in Python. We recommend to use tailored solutions for large arrays and
not standard file storage tools such as `pickle` (`cPickle` for speed
in Python version 2) and `shelve`, because the tailored solutions have
been optimized for array data and are hence much faster than the
standard tools.

===== Using `savez` to store arrays in files =====
label{softeng2:wave1D:filestorage:savez}

=== Storing individual arrays ===

idx{`savez`} idx{`storez`} idx{`load`} idx{zip archive}

The `numpy.storez` function can store a set of arrays to a named
file in a zip archive. An associated function
`numpy.load` can be used to read the file later.
Basically, we call `numpy.storez(filename, **kwargs)`, where
`kwargs` is a dictionary containing array names as keys and
the corresponding array objects as values. Very often, the
solution at a time point is given a natural name where the
name of the variable and the time level counter are combined, e.g.,
`u11` or `v39`. Suppose `n` is the time level counter and we have
two solution arrays, `u` and `v`, that we want to save to a zip
archive. The appropriate code is

!bc pycod
import numpy as np
u_name = 'u%04d' % n   # array name
v_name = 'v%04d' % n   # array name
kwargs = {u_name: u, v_name: v}   # keyword args for savez
fname = '.mydata%04d.dat' % n
np.savez(fname, **kwargs)
if n == 0:           # store x once
    np.savez('.mydata_x.dat', x=x)
!ec
Since the name of the array must be given as a keyword argument
to `savez`, and the name must be constructed as shown, it becomes
a little tricky to do the call, but with a dictionary `kwargs` and
`**kwargs`, which sends each key-value pair as individual keyword
arguments, the task gets accomplished.

=== Merging zip archives ===

Each separate call to `np.savez` creates a new file (zip archive) with
extension `.npz`. It is very convenient to collect all results in
one archive instead. This can be done by merging all the individual
`.npz` files into a single zip archive:

@@@CODE src-wave/wave1D/wave1D_dn_vc.py fromto: def merge@class Plot
Here we remark that `savez` automatically
adds the `.npz` extension to the names of
the arrays we store. We do not want this extension in the final
archive.

=== Reading arrays from zip archives ===

Archives created by `savez` or the merged archive we describe
above with name of the form `myarchive.npz`,
can be conveniently read by the `numpy.load` function:

!bc pycod
import numpy as np
array_names = np.load(`myarchive.npz`)
for array_name in array_names:
    # array_names[array_name] is the array itself
    # e.g. plot(array_names['t'], array_names[array_name])
!ec



===== Using `joblib` to store arrays in files =====
label{softeng2:wave1D:filestorage:joblib}

idx{`joblib`} idx{memoize function} idx{hash}

The Python package `joblib` has nice functionality for efficient storage
of arrays on disk. The following class applies this functionality so that
one can save an array, or in fact any Python data structure (e.g., a
dictionary of arrays), to disk under a certain name. Later, we can
retrieve the object by use of its name. The name of the directory under which
the arrays are stored by `joblib` can be given by the user.

@@@CODE src-softeng2/Storage.py
The `retrive` and `save` functions, which do the work, seem quite
magic. The idea is that `joblib` looks at the `name` parameter
and saves the return value `data` to disk if the `name` parameter
has not been used in a previous call. Otherwise, if `name` is
already registered, `joblib` fetches the `data` object from
file and returns it (this is an example of a memoize function,
see Section 2.1.4 in cite{Langtangen_scaling} for a brief explanation]).

===== Using a hash to create a file or directory name =====
label{softeng2:wave1D:filestorage:hash}

Array storage techniques like those outlined in Sections
ref{softeng2:wave1D:filestorage:joblib} and
ref{softeng2:wave1D:filestorage:savez} demand the user to assign a
name for the file(s) or directory where the solution is to be
stored. Ideally, this name should reflect parameters in the problem
such that one can recognize an already run simulation. One technique
is to make a hash string out of the input data.  A hash string is a
40-character long hexadecimal string that uniquely reflects another
potentially much longer string. (You may be used to hash strings from
the Git version control system: every committed version of the files
in Git is recognized by a hash string.)

Suppose you have some input data in the form of functions,
`numpy` arrays, and other objects. To turn these input data
into a string, we may grab the source code of the functions,
use a very efficient hash method for potentially large arrays,
and simply convert all other objects via `str` to a string
representation. The final string, merging all input data,
is then converted to an SHA1 hash string such that we represent
the input with a 40-character long string.

!bc pycod
def myfunction(func1, func2, array1, array2, obj1, obj2):
    # Convert arguments to hash
    import inspect, joblib, hashlib
    data = (inspect.getsource(func1),
            inspect.getsource(func2),
	    joblib.hash(array1),
	    joblib.hash(array2),
	    str(obj1),
	    str(obj2))
    hash_input = hashlib.sha1(data).hexdigest()
!ec
It is wise to use `joblib.hash` and not try to do a
`str(array1)`, since that string can be *very* long, and
`joblib.hash` is more efficient than `hashlib` when turning
these data into a hash.

!bwarning Remark: turning function objects into their source code is unreliable!
The idea of turning a function object into a string via its source code
may look smart, but is not a completely reliable solution.
Suppose we have some function

!bc pycod
x0 = 0.1
f = lambda x: 0 if x <= x0 else 1
!ec
The source code will be `f = lambda x: 0 if x <= x0 else 1`, so if the
calling code changes the value of `x0` (which `f` remembers - it is
a closure), the source remains unchanged, the hash is the same,
and the change in input data is unnoticed. Consequently, the technique
above must be used with care. The user can always just remove the
stored files in disk and thereby force a recomputation (provided the software
applies a hash to test if a zip archive or `joblib` subdirectory
exists, and if so, avoids recomputation).
!ewarning

======= Software for the 1D wave equation =======

#-----------
We use `numpy.storez` to store the solution at each time level on disk.
Such actions must be
taken care of outside the `solver` function, more precisely in the
`user_action` function that is called at every time level.

We have, in the "`wave1D_dn_vc.py`": "${src_wave}/wave1D/wave_dn_vc.py"
code, implemented the `user_action`
callback function as a class `PlotAndStoreSolution` with a
`__call__(self, x, t, t, n)` method for the `user_action` function.
Basically, `__call__` stores and plots the solution.
The storage makes use of the `numpy.savez` function for saving
a set of arrays to a zip archive.
Here, in this callback function, we want to save one array, `u`.
Since there will be many such arrays, we introduce the array names
`'u%04d' % n` and closely related filenames.
The usage of `numpy.savez` in `__call__` goes like this:

!bc pycod
from numpy import savez
name = 'u%04d' % n   # array name
kwargs = {name: u}   # keyword args for savez
fname = '.' + self.filename + '_' + name + '.dat'
self.t.append(t[n])  # store corresponding time value
savez(fname, **kwargs)
if n == 0:           # store x once
    savez('.' + self.filename + '_x.dat', x=x)
!ec
For example, if `n` is 10 and `self.filename` is `tmp`,
the above call to `savez` becomes
`savez('.tmp_u0010.dat', u0010=u)`.
The actual filename becomes `.tmp_u0010.dat.npz`. The actual array
name becomes `u0010.npy`.

Each `savez` call results in a file, so after the simulation we have
one file per time level. Each file produced by `savez` is a zip archive.
It makes sense to merge all the files into one. This is done in
the `close_file` method in the `PlotAndStoreSolution` class. The code goes as
follows.

!bc pycod
class PlotAndStoreSolution:
    ...
    def close_file(self, hashed_input):
        """
        Merge all files from savez calls into one archive.
        hashed_input is a string reflecting input data
        for this simulation (made by solver).
        """
        if self.filename is not None:
            # Save all the time points where solutions are saved
            savez('.' + self.filename + '_t.dat',
                  t=array(self.t, dtype=float))
            # Merge all savez files to one zip archive
            archive_name = '.' + hashed_input + '_archive.npz'
            filenames = glob.glob('.' + self.filename + '*.dat.npz')
            merge_zip_archives(filenames, archive_name)
!ec
We use various `ZipFile` functionality to extract the content of the
individual files (each with name `filename`) and write it to the
merged archive (`archive`).  There is only one
array in each individual file (`filename`) so strictly speaking, there
is no need for the loop `for name in f.namelist()` (as `f.namelist()`
returns a list of length 1). However, in other applications where
we compute more arrays at each time level, `savez` will store all
these and then there is need for iterating over `f.namelist()`.

Instead of merging the archives written by `savez` we could make
an alternative implementation that writes all our arrays into
one archive. This is the subject of Exercise ref{softeng2:exer:savez}.


===== Making hash strings from input data =====
label{softeng2:wave1D:filestorage:hashlib}

The `hashed_input` argument, used to name the
resulting archive file with all solutions, is supposed to be a
hash reflecting all import parameters in the problem such that this
simulation has a unique name.
The `hashed_input` string is made in the "`solver`":
"${src_wave}/wave1D/wave_dn_vc.py" function, using the `hashlib`
and `inspect` modules, based on the arguments to `solver`:

!bc pycod
# Make hash of all input data
import hashlib, inspect
data = inspect.getsource(I) + '_' + inspect.getsource(V) + \
       '_' + inspect.getsource(f) + '_' + str(c) + '_' + \
       ('None' if U_0 is None else inspect.getsource(U_0)) + \
       ('None' if U_L is None else inspect.getsource(U_L)) + \
       '_' + str(L) + str(dt) + '_' + str(C) + '_' + str(T) + \
       '_' + str(stability_safety_factor)
hashed_input = hashlib.sha1(data).hexdigest()
!ec

To get the source code of a function `f` as a string,
we use `inspect.getsource(f)`. All input, functions as
well as variables, is then merged
to a string `data`, and then `hashlib.sha1` makes a unique, much shorter
(40 characters long),
fixed-length string out of `data` that we can use in the archive filename.

!bwarning Remark
Note that the construction of the `data` string is not fool proof:
if, e.g., `I` is a formula with parameters and the parameters change,
the source code is still the same and `data` and hence the hash remains
unaltered. The implementation must therefore be used with care!
!ewarning

===== Avoiding rerunning previously run cases =====
label{softeng2:wave1D:filestorage:norerun}

If the archive file whose name is based on `hashed_input` already
exists, the simulation with the current set of parameters has been
done before and one can avoid redoing the work. The `solver` function
returns the CPU time and `hashed_input`, and a negative CPU time means
that no simulation was run. In that case we should not call
the `close_file` method above (otherwise we overwrite the archive with
just the `self.t` array). The typical usage goes like

!bc pycod
action = PlotAndStoreSolution(...)
dt = (L/Nx)/C  # choose the stability limit with given Nx
cpu, hashed_input = solver(
    I=lambda x: ...,
    V=0, f=0, c=1, U_0=lambda t: 0, U_L=None, L=1,
    dt=dt, C=C, T=T,
    user_action=action, version='vectorized',
    stability_safety_factor=1)
action.make_movie_file()
if cpu > 0:  # did we generate new data?
    action.close_file(hashed_input)
!ec

===== Verification =====

=== Vanishing approximation error ===

Exact solutions of the numerical equations are always attractive for
verification purposes since the software should reproduce such
solutions to machine precision. With Dirichlet boundary conditions
we can construct a function that is linear in $t$ and quadratic in
$x$ that is also an exact solution of the scheme, while with Neumann
conditions we are left with testing just a constant solution
(see comments in ref[Section ref{wave:pde1:verify}][ in
cite{Langtangen_deqbook_wave}][in
the document "Finite difference methods for wave motion":
"http://tinyurl.com/k3sdbuv/pub/wave"
cite{Langtangen_deqbook_wave}]).

=== Convergence rates ===

idx{verification! convergence rates}

A more general method for verification is to check the convergence rates.
We must introduce one discretization parameter $h$ and assume an error
model $E=Ch^r$, where $C$ and $r$ are constants to be determine (i.e.,
$r$ is the rate that we are interested in). Given two experiments with
different resolutions $h_i$ and $h_i{-1}$, we can estimate $r$ by

!bt
\[ r = \frac{\ln(E_{i}/E_{i-1})}{\ln(h_{i}/h_{i-1})},\]
!et
where $E_i$ is the error corresponding to $h_i$ and $E_{i-1}$ corresponds to
$h_{i-1}$. ref[Section ref{wave:pde2:fd:standing:waves}][ in cite{Langtangen_deqbook_wave}][The
section "Using an analytical solution of physical significance": ""
in cite{Langtangen_deqbook_wave}] explains the details of this type of verification and how
we introduce the single discretization parameter $h=\Delta t = \hat c\Delta t$,
for some constant $\hat c$. To compute the error, we had to rely on
a global variable in the user action function. Below is an implementation
where we have a more elegant solution in terms of a class: the `error`
variable is not a class attribute and there is no need for a global
error (which is always considered an advantage).

@@@CODE src-wave/wave1D/wave1D_dn_vc.py def convergence_rates@def test_convrate_sincos
The returned sequence `r` should converge to 2 since the error
analysis in ref[Section ref{wave:pde1:analysis}][in
cite{Langtangen_deqbook_wave}][the section "Analysis of the difference
equations": "" in cite{Langtangen_deqbook_wave}] predicts various error measures to behave
like $\Oof{\Delta t^2} + \Oof{\Delta x^2}$. We can easily run
the case with standing waves and the analytical solution
$u(x,t) = \cos(\frac{2\pi}{L}t)\sin(\frac{2\pi}{L}x)$. The call will
be very similar to the one provided in the `test_convrate_sincos` function
in ref[Section ref{wave:pde1:impl:verify:rate}][ in cite{Langtangen_deqbook_wave}][the section "Verification: convergence rates": "" in
cite{Langtangen_deqbook_wave}], see the file "`wave1D_dn_vc.py`":
"${src_wave}/wave1D/wave_dn_vc.py" for details.


======= Programming the solver with classes =======

idx{`wave1D_oo.py`}

Many who know about class programming prefer to organize their software
in terms of classes. This gives a richer application programming interface
(API) since a function solver must have all its input data in terms
of arguments, while a class-based solver naturally has a mix of method
arguments and user-supplied methods. (Well, to be more precise,
our solvers have demanded `user_action`
to be a function provided by the user, so it is possible to mix variables
and functions in the input also with a solver function.)

We will next illustrate how some of the functionality in `wave1D_dn_vc.py`
may be implemented by using classes. Focusing on class implementation aspects,
we restrict the example case to a simpler wave with constant wave speed $c$.
Applying the method of manufactured solutions, we test whether the class based
implementation is able to compute the known exact solution within machine precision.

We will create a class `Problem` to hold the physical parameters of the
problem and a class `Solver` to hold the numerical solution parameters besides
the solver function itself. As the number of parameters increases, so does
the amount of repetitive code. We therefore take the opportunity to illustrate
how this may be counteracted by introducing a super class `Parameters` that allows 
code to be parameterized. In addition, it is convenient to collect the
arrays that describe the mesh in a special `Mesh` class and make
a class `Function` for a mesh function (mesh point values and its mesh).
All the following code is found in "`wave1D_oo.py`": "${src_softeng2}/wave1D_oo.py".

===== Class Parameters =====

The classes `Problem` and `Solver` both inherit class `Parameters`, which
handles reading of parameters from the command line and has methods 
for setting and getting parameter values. Since processing dictionaries
is easier than processing a collection of individual attributes, the class 
`Parameters` requires each class `Problem` and `Solver` to represent their 
parameters by dictionaries, one compulsory and two optional ones. The compulsory dictionary, `self.prm`, contains all parameters, while a second and optional dictionary, `self.type`, holds the associated object types, and a third and optional dictionary, `self.help`, stores help strings. The `Parameters` class may be implemented as follows:

@@@CODE src-softeng2/wave1D_oo.py fromto: class Parameters@class Problem


===== Class Problem =====

Inheriting the `Parameters` class, our class `Problem` is defined as:

@@@CODE src-softeng2/wave1D_oo.py fromto: class Problem@class Solver


===== Class Mesh =====

The `Mesh` class can be made valid for a space-time mesh in any number
of space dimensions. To make the class versatile, the constructor accepts
either a tuple/list of number of cells in each spatial dimension or
a tuple/list of cell spacings. In addition, we need the size of the
hypercube mesh as a tuple/list of 2-tuples with lower and upper limits
of the mesh coordinates in each direction. For 1D meshes it is more
natural to just write the number of cells or the cell size and not
wrap it in a list. We also need the time
interval from `t0` to `T`. Giving no spatial discretization information
implies a time mesh only, and vice versa. The `Mesh` class with
documentation and a doc test should now be self-explanatory:

@@@CODE src-softeng2/UniformFDMesh.py fromto: import numpy@class Function

!bnotice We rely on attribute access - not get/set functions!
Java programmers, in particular, are used to get/set functions in
classes to access internal data. In Python, we usually apply direct
access of the attribute, such as `m.N[i]` if `m` is a `Mesh` object.
A widely used convention is to do this as long as access to
an attribute does not require additional code. In that case, one
applies a property construction. The original interface remains
the same after a property is introduced (in contrast to Java), so
user will not notice a change to properties.

The only argument against direct attribute access in class `Mesh`
is that the attributes are read-only so we could avoid offering
a set function. Instead, we rely on the user that she does not
assign new values to the attributes.
!enotice

===== Class Function =====

A class `Function` is handy to hold a mesh and corresponding values for
a scalar or vector function over the mesh. Since we may have a
time or space mesh, or a combined time and space mesh, with one or
more components in the function, some if tests are needed for
allocating the right array sizes. To help the user, an `indices`
attribute with the name of the indices in the final array `u`
for the function values is made. The examples in the doc string
should explain the functionality.

@@@CODE src-softeng2/UniformFDMesh.py fromto: class Function@if __name

===== Class Solver =====

With the `Mesh` and `Function` classes in place, we can rewrite
the `solver` function, but we make it a method in class `Solver`:

[hpl: Rewrite solver!]

@@@CODE src-softeng2/wave1D_oo.py fromto: class Solver@def test

Observe that the solutions from all time steps are stored in the mesh function, 
which allows error assessment (in `assert_no_error`) to take place after all 
solutions have been found. Of course, in 2D or 3D, such a strategy may place too
high demands on available computer memory, in which case intermediate results
could be stored on file.

Running `wave1D_oo.py` gives a printout showing that the class-based 
implementation performs as expected, i.e. that the known exact solution
is reproduced (within machine precision).


======= Migrating loops to Cython =======
label{wave2D3D:impl:Cython}

idx{Cython} idx{`wave2D_u0.py`} idx{`wave2D_u0_adv.py`}

We now consider the "`wave2D_u0.py`": "${src_wave}/wave2D_u0/wave2D_u0.py"
code for solving the 2D linear wave equation with constant wave
velocity and homogeneous Dirichlet boundary conditions $u=0$.
We shall in the present chapter extend this code with computational
modules written in other languages than Python. This extended version is
called "`wave2D_u0_adv.py`": "${src_softeng2}/wave2D_u0_adv.py".

The `wave2D_u0.py` file contains a `solver` function, which calls an
`advance_*` function to advance the numerical scheme one level forward
in time.  The function `advance_scalar` applies standard Python loops
to implement the scheme, while `advance_vectorized` performs
corresponding vectorized arithmetics with array slices. The statements
of this solver are explained in ref[Section ref{wave:2D3D:impl}, in
particular Sections ref{wave2D3D:impl:scalar} and
ref{wave2D3D:impl:vectorized}][ in cite{Langtangen_deqbook_wave}][in
the document "Finite difference methods for wave motion":
"http://tinyurl.com/k3sdbuv/pub/wave" cite{Langtangen_deqbook_wave}].

Although vectorization can bring down the CPU time dramatically
compared with scalar code, there is still some factor 5-10 to win in
these types of applications by implementing the finite difference
scheme in compiled code, typically in Fortran, C, or C++. This can
quite easily be done by adding a little extra code to our
program. Cython is an extension of Python that offers the easiest way
to nail our Python loops in the scalar code down to machine code and
achieve the efficiency of C.

Cython can be viewed as an extended Python language where variables
are declared with types and where functions are marked to be
implemented in C.  Migrating Python code to Cython is done by copying
the desired code segments to functions (or classes) and placing them
in one or more separate files with extension `.pyx`.

===== Declaring variables and annotating the code =====

idx{`wave2D_u0_loop_cy.pyx`}

Our starting point is the plain `advance_scalar` function for a scalar
implementation of the updating algorithm for new values
$u^{n+1}_{i,j}$:

@@@CODE src-wave/wave2D_u0/wave2D_u0.py fromto: def advance_scalar@def advance_ve

We simply take
a copy of this function and put it in a file `wave2D_u0_loop_cy.pyx`.
The relevant Cython implementation arises from declaring variables with
types and adding some important annotations to speed up array
computing in Cython. Let us first list the complete code in the
`.pyx` file:

@@@CODE src-softeng2/wave2D_u0_loop_cy.pyx

idx{declaration of variables in Cython}

This example may act as a recipe on how to transform array-intensive
code with loops into Cython.

 o Variables are declared with types: for example,
   `double v` in the argument list instead of just `v`, and `cdef double v`
   for a variable `v` in the body of the function.
   A Python `float` object is declared as `double` for
   translation to C by Cython, while an `int` object is
   declared by `int`.
 o Arrays need a comprehensive type declaration involving
   * the type `np.ndarray`,
   * the data type of the elements, here 64-bit floats,
     abbreviated as `DT` through `ctypedef np.float64_t DT`
     (instead of `DT` we could use the full name of the
     data type: `np.float64_t`, which is a Cython-defined type),
   * the dimensions of the array, here `ndim=2` and `ndim=1`,
   * specification of contiguous memory for the array (`mode='c'`).
 o Functions declared with `cpdef` are translated to C but are also
   accessible from Python.
 o In addition to the standard `numpy` import we also need a special
   Cython import of `numpy`: `cimport numpy as np`, to appear *after*
   the standard import.
 o By default, array indices are checked to be within their legal
   limits. To speed up the code one should turn off this feature
   for a specific function by placing `@cython.boundscheck(False)`
   above the function header.
 o Also by default, array indices can be negative (counting from the
   end), but this feature has a performance penalty and is therefore
   here turned off by writing `@cython.wraparound(False)` right above
   the function header.
 o The use of index sets `Ix` and `Iy` in the scalar code cannot be
   successfully translated to C. One reason is that constructions like
   `Ix[1:-1]` involve negative indices, and these are now turned
   off. Another reason is that Cython loops must take the form `for i
   in xrange` or `for i in range` for being translated into efficient
   C loops. We have therefore introduced `Ix_start` as `Ix[0]`
   and `Ix_end` as `Ix[-1]` to hold the start and end of the values
   of index $i$. Similar variables are introduced for the $j$ index.
   A loop `for i in Ix` is with these new variables written as
   `for i in range(Ix_start, Ix_end+1)`.


!bnotice Array declaration syntax in Cython
We have used the syntax `np.ndarray[DT, ndim=2, mode='c']` to declare
`numpy` arrays in Cython. There is a simpler, alternative syntax, employing
"typed memory views": "http://docs.cython.org/src/userguide/memoryviews.html",
where the declaration looks like `double [:,:]`.
However, the full support for this functionality is not yet ready, and
in this text we use the full array declaration syntax.
!enotice

===== Visual inspection of the C translation =====

idx{`cython -a` (Python-C translation in HTML)}

Cython can visually explain how successfully it translated a code from
Python to C. The command

!bc sys
Terminal> cython -a wave2D_u0_loop_cy.pyx
!ec
produces an HTML file `wave2D_u0_loop_cy.html`, which can be loaded into
a web browser to illustrate which lines of the code that have been
translated to C. Figure ref{wave:2D3D:impl:fig:cython:ma1} shows
the illustrated code. Yellow lines indicate the lines that Cython did not manage
to translate to efficient C code and that remain in Python.
For the present code we see that Cython is able to translate all the
loops with array computing to C, which is our primary goal.

FIGURE: [fig-softeng2/wave2D_u0_loop_cy1, width=500 frac=0.8] Visual illustration of Cython's ability to translate Python to C. label{wave:2D3D:impl:fig:cython:ma1}

You can also inspect the generated C code directly, as it appears in
the file `wave2D_u0_loop_cy.c`. Nevertheless, understanding this C
code requires some familiarity with writing Python extension modules
in C by hand.  Deep down in the file we can see in detail how the
compute-intensive statements have been translated into some complex C
code that is quite different from what a human would write (at
least if a direct correspondence to the mathematical notation was
intended).


===== Building the extension module =====

idx{C extension module}
idx{`setup.py`}
idx{`distutils`}

Cython code must be translated to C, compiled, and linked to form what
is known in the Python world as a *C extension module*.
This is usually done by making a `setup.py` script, which
is the standard way of building and installing Python software.
For an extension module arising from Cython code, the following
`setup.py` script is all we need to build and install the module:

!bc pycod
from distutils.core import setup
from distutils.extension import Extension
from Cython.Distutils import build_ext

cymodule = 'wave2D_u0_loop_cy'
setup(
  name=cymodule
  ext_modules=[Extension(cymodule, [cymodule + '.pyx'],)],
  cmdclass={'build_ext': build_ext},
)
!ec
We run the script by

!bc sys
Terminal> python setup.py build_ext --inplace
!ec
The `--inplace` option makes the extension module available in the
current directory as the file `wave2D_u0_loop_cy.so`. This
file acts as a normal Python module that can be imported and inspected:

!bc ipy
>>> import wave2D_u0_loop_cy
>>> dir(wave2D_u0_loop_cy)
['__builtins__', '__doc__', '__file__', '__name__',
 '__package__', '__test__', 'advance', 'np']
!ec
The important output from the `dir` function is our Cython function
`advance` (the module also features the imported `numpy` module under
the name `np` as well as many standard Python objects with double
underscores in their names).

The `setup.py` file makes use of the `distutils` package in Python
and Cython's extension of this package.
These tools know how Python was built on the computer and will
use compatible compiler(s) and options when building other code
in Cython, C, or C++. Quite some experience with building large
program systems is needed to do the build process manually, so using
a `setup.py` script is strongly recommended.

!bnotice Simplified build of a Cython module
When there is no need to link the C code with special libraries,
Cython offers a shortcut for generating and importing the extension
module:

!bc pycod
import pyximport; pyximport.install()
!ec
This makes the `setup.py` script redundant. However, in the `wave2D_u0_adv.py`
code we do not use `pyximport` and require an explicit build process
of this and many other modules.
!enotice

===== Calling the Cython function from Python =====

The `wave2D_u0_loop_cy`
module contains our `advance` function, which we now may call from
the Python program for the wave equation:

!bc pycod
import wave2D_u0_loop_cy
advance = wave2D_u0_loop_cy.advance
...
for n in It[1:-1]:                  # time loop
    f_a[:,:] = f(xv, yv, t[n])     # precompute, size as u
    u = advance(u, u_n, u_nm1, f_a, x, y, t, Cx2, Cy2, dt2)
!ec

=== Efficiency ===

For a mesh consisting of $120\times 120$ cells, the scalar Python code
require 1370 CPU time units, the vectorized version requires 5.5,
while the Cython version requires only 1! For a smaller mesh with
$60\times 60$ cells Cython is about 1000 times faster than the scalar
Python code, and the vectorized version is about 6 times slower than
the Cython version.

#In 3D these numbers are even more favorable.

======= Migrating loops to Fortran =======

idx{Fortran 77}

Instead of relying on Cython's (excellent) ability to translate Python to C,
we can invoke a compiled language directly and write the loops ourselves.
Let us start with Fortran 77, because this is a language with more
convenient array handling than C (or plain C++), because
we can use the same multi-dimensional indices
in the Fortran code as in the `numpy`
arrays in the Python code, while in C these arrays are
one-dimensional and require us to reduce multi-dimensional indices
to a single index.

#Fortran compilers
#build on 60 years of intensive research on how to optimize loops with
#array computations.

===== The Fortran subroutine =====

idx{wrapper code}
idx{Fortran subroutine}
idx{`wave2D_u0_loop_f77.f`}

We write a Fortran subroutine `advance` in a file
"`wave2D_u0_loop_f77.f`": "${src_wave}/wave2D_u0/wave2D_u0_loop_f77.f"
for implementing the updating formula
(ref{wave:2D3D:impl1:2Du0:ueq:discrete}) and setting the solution to zero
at the boundaries:

@@@CODE src-softeng2/wave2D_u0_loop_f77.f
This code is plain Fortran 77, except for the special `Cf2py` comment
line, which here specifies that `u` is both an input argument *and*
an object to be returned from the `advance` routine. Or more
precisely, Fortran is not able return an array from a function,
but we need a *wrapper code* in C for the Fortran subroutine to enable
calling it from Python, and from this wrapper code one can return `u`
to the calling Python code.

!bnotice Tip: Return all computed objects to the calling code
It is not strictly necessary to return `u` to the calling Python
code since the `advance` function will modify the elements of `u`,
but the convention in Python is to get all output from a function
as returned values. That is, the right way of calling the above
Fortran subroutine from Python is

!bc pycod
u = advance(u, u_n, u_nm1, f, Cx2, Cy2, dt2)
!ec
The less encouraged style, which works and resembles the way the
Fortran subroutine is called from Fortran, reads

!bc pycod
advance(u, u_n, u_nm1, f, Cx2, Cy2, dt2)
!ec
!enotice

===== Building the Fortran module with f2py =====

idx{Fortran 90}

The nice feature of writing loops in Fortran is that, without
much effort, the tool `f2py`
can produce a C extension module such that
we can call the Fortran version of `advance` from Python.
The necessary commands to run are

!bc sys
Terminal> f2py -m wave2D_u0_loop_f77 -h wave2D_u0_loop_f77.pyf \
          --overwrite-signature wave2D_u0_loop_f77.f
Terminal> f2py -c wave2D_u0_loop_f77.pyf --build-dir build_f77 \
          -DF2PY_REPORT_ON_ARRAY_COPY=1 wave2D_u0_loop_f77.f
!ec
The first command asks `f2py` to interpret the Fortran code and make
a Fortran 90
specification of the extension module in the file
`wave2D_u0_loop_f77.pyf`. The second command makes
`f2py` generate all necessary
wrapper code, compile our Fortran file and the wrapper code,
and finally build the module.
The build process takes place in the specified subdirectory `build_f77`
so that files can be inspected if something goes wrong.
The option `-DF2PY_REPORT_ON_ARRAY_COPY=1` makes `f2py` write a message
for every array that is copied in the communication between Fortran and Python,
which is very useful for avoiding unnecessary array copying (see below).
The name of the module file
is `wave2D_u0_loop_f77.so`, and this file can be imported and inspected
as any other
Python module:

!bc ipy
>>> import wave2D_u0_loop_f77
>>> dir(wave2D_u0_loop_f77)
['__doc__', '__file__', '__name__', '__package__',
 '__version__', 'advance']
>>> print wave2D_u0_loop_f77.__doc__
This module 'wave2D_u0_loop_f77' is auto-generated with f2py....
Functions:
  u = advance(u,u_n,u_nm1,f,cx2,cy2,dt2,
      nx=(shape(u,0)-1),ny=(shape(u,1)-1))
!ec


!bwarning Examine the doc strings!
Printing the doc strings of the module and its functions is
extremely important after having created a module with `f2py`.
The reason is that
`f2py` makes Python interfaces to the Fortran functions
that are different from how the functions are declared in
the Fortran code (!). The rationale for this behavior is that
`f2py` creates *Pythonic* interfaces such that Fortran routines
can be called in the same way as one calls Python functions.
Output data from Python functions is always returned
to the calling code, but this is technically impossible in Fortran.
Also, arrays in Python are passed to Python functions without
their dimensions because that information is packed with the array
data in the array objects. This is not possible in Fortran, however.
Therefore, `f2py` removes array dimensions from the argument list,
and `f2py` makes it possible to
return objects back to Python.
!ewarning

Let us follow the advice of examining the doc strings
and take a close look at
the documentation `f2py` has generated for our Fortran `advance`
subroutine:

!bc ipy
>>> print wave2D_u0_loop_f77.advance.__doc__
This module 'wave2D_u0_loop_f77' is auto-generated with f2py
Functions:
  u = advance(u,u_n,u_nm1,f,cx2,cy2,dt2,
              nx=(shape(u,0)-1),ny=(shape(u,1)-1))
.
advance - Function signature:
  u = advance(u,u_n,u_nm1,f,cx2,cy2,dt2,[nx,ny])
Required arguments:
  u : input rank-2 array('d') with bounds (nx + 1,ny + 1)
  u_n : input rank-2 array('d') with bounds (nx + 1,ny + 1)
  u_nm1 : input rank-2 array('d') with bounds (nx + 1,ny + 1)
  f : input rank-2 array('d') with bounds (nx + 1,ny + 1)
  cx2 : input float
  cy2 : input float
  dt2 : input float
Optional arguments:
  nx := (shape(u,0)-1) input int
  ny := (shape(u,1)-1) input int
Return objects:
  u : rank-2 array('d') with bounds (nx + 1,ny + 1)
!ec
Here we see that the `nx` and `ny` parameters declared in
Fortran are optional arguments that can be omitted when calling
`advance` from Python.

We strongly recommend to print out the
documentation of *every* Fortran function to be called from Python
and make sure the call syntax is exactly as listed in the
documentation.


===== How to avoid array copying =====

idx{row-major ordering}
idx{column-major ordering}
idx{Fortran array storage}
idx{C/Python array storage}

Multi-dimensional arrays are stored as a stream of numbers in memory.
For a two-dimensional array consisting of rows and columns there are
two ways of creating such a stream: *row-major ordering*, which means
that rows are stored consecutively in memory, or *column-major
ordering*, which means that the columns are stored one after each other.
All programming languages inherited from C, including Python, apply
the row-major ordering, but Fortran uses column-major storage.
Thinking of a two-dimensional array in Python or C
as a matrix, it means that Fortran
works with the transposed matrix.

Fortunately, `f2py` creates extra code so that accessing `u(i,j)` in
the Fortran subroutine corresponds to the element `u[i,j]` in the
underlying `numpy` array (without the extra code, `u(i,j)` in Fortran
would access `u[j,i]` in the `numpy` array).  Technically, `f2py`
takes a copy of our `numpy` array and reorders the data before
sending the array to Fortran. Such copying can be costly. For 2D wave
simulations on a $60\times 60$ grid the overhead of copying is a
factor of 5, which means that almost the whole performance gain of
Fortran over vectorized `numpy` code is lost!

To avoid having `f2py` to copy
arrays with C storage to the corresponding Fortran storage, we declare
the arrays with Fortran storage:

!bc pycod
order = 'Fortran' if version == 'f77' else 'C'
u   = zeros((Nx+1,Ny+1), order=order)   # solution array
u_n = zeros((Nx+1,Ny+1), order=order)   # solution at t-dt
u_nm1 = zeros((Nx+1,Ny+1), order=order)   # solution at t-2*dt
!ec


In the compile and build step of using `f2py`, it is recommended to add
an extra option for making `f2py` report on array copying:

!bc sys
Terminal> f2py -c wave2D_u0_loop_f77.pyf --build-dir build_f77 \
          -DF2PY_REPORT_ON_ARRAY_COPY=1 wave2D_u0_loop_f77.f
!ec

It can sometimes be a challenge to track down which array that causes
a copying. There are two principal reasons for copying array data:
either the array does not have Fortran storage or the element types do
not match those declared in the Fortran code. The latter cause is
usually effectively eliminated by using `real*8` data in the Fortran
code and `float64` (the default `float` type in `numpy`) in the arrays
on the Python side. The former reason is more common, and to check
whether an array before a Fortran call has the right storage one can
print the result of `isfortran(a)`, which is `True` if the array `a`
has Fortran storage.

Let us look at an example where we face problems with array storage.
A typical problem in the `wave2D_u0.py` code is
to set

!bc pycod
f_a = f(xv, yv, t[n])
!ec
before the call to the Fortran `advance` routine. This computation creates
a new array with C storage. An undesired copy of `f_a` will be produced
when sending `f_a` to a Fortran routine.
There are two remedies, either direct insertion
of data in an array with Fortran storage,
!bc pycod
f_a = zeros((Nx+1, Ny+1), order='Fortran')
...
f_a[:,:] = f(xv, yv, t[n])
!ec
or remaking the `f(xv, yv, t[n])` array,
!bc pycod
f_a = asarray(f(xv, yv, t[n]), order='Fortran')
!ec
The former remedy is most efficient if the `asarray` operation is to
be performed a large number of times.

=== Efficiency ===

The efficiency of this Fortran code is very similar to the Cython code.
There is usually nothing more to gain, from a computational efficiency
point of view, by implementing the *complete* Python program in Fortran
or C. That will just be a lot more code for all administering work
that is needed in scientific software, especially if we extend our
sample program `wave2D_u0.py` to handle a real scientific problem.
Then only a small portion will consist of loops with intensive
array calculations. These can be migrated to Cython or Fortran as
explained, while the rest of the programming can be more conveniently
done in Python.

# #ifdef NOTES
 * `f_a` in-place assignment important for Fortran,
   copy of data with f2py
 * pyximport if plain compilation and no linking with external C libraries
   (we build instead)
 * explain pyximport for mc cython and cyode
 * negative_indices wraparound
 * make Grid2D cython (callback - cpdef?) and hello world
 * split HTML files (find all internal # links, make dict where
   links are while reading file and splitting into chunks, replace
   links with filenames), use same split syntax as for sphinx, but
   different bin/doconce routine (read the whole HTML file, grab header,
   search for delimiter lines)

# #endif

======= Migrating loops to C via Cython =======

The computationally intensive loops can alternatively be implemented
in C code. Just as Fortran calls for care regarding the storage of
two-dimensional arrays, working with two-dimensional arrays in C
is a bit tricky. The reason is that
`numpy` arrays are viewed as one-dimensional arrays when
transferred to C, while C programmers will think of `u`, `u_n`, and
`u_nm1` as two dimensional arrays and index them like `u[i][j]`.
The C code must declare `u` as `double* u` and translate an index
pair `[i][j]` to a corresponding single index when `u` is
viewed as one-dimensional. This translation requires knowledge of
how the numbers in `u` are stored in memory.

===== Translating index pairs to single indices =====

Two-dimensional `numpy` arrays with the default C storage are stored
row by row. In general, multi-dimensional arrays with C storage are
stored such that the last index has the fastest variation, then the
next last index, and so on, ending up with the slowest variation
in the first index. For a two-dimensional `u` declared as
`zeros((Nx+1,Ny+1))` in Python, the individual elements are stored
in the following order:

!bc pycod
u[0,0], u[0,1], u[0,2], ..., u[0,Ny], u[1,0], u[1,1], ...,
u[1,Ny], u[2,0], ..., u[Nx,0], u[Nx,1], ..., u[Nx, Ny]
!ec

Viewing `u` as one-dimensional, the index pair $(i,j)$ translates
to $i(N_y+1)+j$. So, where a C programmer would naturally write
an index `u[i][j]`, the indexing must read `u[i*(Ny+1) + j]`.
This is tedious to write, so it can be handy to define a C macro,

!bc ccod
#define idx(i,j) (i)*(Ny+1) + j
!ec
so that we can write `u[idx(i,j)]`, which reads much better and is
easier to debug.

!bwarning Be careful with macro definitions
Macros just perform simple text substitutions:
`idx(hello,world)` is expanded to `(hello)*(Ny+1) + world`.
The parentheses in `(i)` are essential - using the natural mathematical
formula `i*(Ny+1) + j` in the macro definition,
`idx(i-1,j)` would expand to `i-1*(Ny+1) + j`, which is the wrong
formula. Macros are handy, but require careful use.
In C++, inline functions are safer and replace the need for macros.
!ewarning

===== The complete C code =====

The C version of our function `advance` can be coded as follows.

@@@CODE src-softeng2/wave2D_u0_loop_c.c

===== The Cython interface file =====

idx{`wave2D_u0_loop_c.c`} idx{`wave2D_u0_loop_c.h`}

All the code above appears in a file "`wave2D_u0_loop_c.c`":
"${src_wave}//wave2D_u0/wave2D_u0_loop_c.c".
We need to compile this file together with C wrapper code such that
`advance` can be called from Python. Cython can be used to generate
appropriate wrapper code.
The relevant Cython code for interfacing C is
placed in a file with extension `.pyx`. Here this file, called
"`wave2D_u0_loop_c_cy.pyx`":
"${src_wave}/wave2D_u0/wave2D_u0_loop_c_cy.pyx", looks like

@@@CODE src-softeng2/wave2D_u0_loop_c_cy.pyx
We first declare the C functions to be interfaced.
These must also appear in a C header file, "`wave2D_u0_loop_c.h`":
"${src_wave}/wave2D_u0/wave2D_u0_loop_c.h",

@@@CODE src-softeng2/wave2D_u0_loop_c.h
The next step is to write a Cython function with Python objects as arguments.
The name `advance` is already used for the C function so the function
to be called from Python is named `advance_cwrap`. The contents of
this function is simply a call to the `advance` version in C. To this end,
the right information from the Python objects must be passed on as
arguments to `advance`. Arrays are sent with their C pointers to the
first element, obtained in Cython as `&u[0,0]` (the `&` takes the
address of a C variable). The `Nx` and `Ny` arguments in `advance` are
easily obtained from the shape of the `numpy` array `u`.
Finally, `u` must be returned such that we can set `u = advance(...)`
in Python.

===== Building the extension module =====

It remains to build the extension module. An appropriate
`setup.py` file is

@@@CODE src-softeng2/setup_wave2D_u0_loop_c_cy.py
All we need to specify is the `.c` file(s) and the `.pyx` interface
file. Cython is automatically run to generate the necessary wrapper
code. Files are then compiled and linked to an extension module
residing in the file `wave2D_u0_loop_c_cy.so`. Here is a
session with running `setup.py`
and examining the resulting module in Python

!bc sys
Terminal> python setup.py build_ext --inplace
Terminal> python
>>> import wave2D_u0_loop_c_cy as m
>>> dir(m)
['__builtins__', '__doc__', '__file__', '__name__', '__package__',
 '__test__', 'advance_cwrap', 'np']
!ec
The call to the C version of `advance` can go like this in Python:

!bc pycod
import wave2D_u0_loop_c_cy
advance = wave2D_u0_loop_c_cy.advance_cwrap
...
f_a[:,:] = f(xv, yv, t[n])
u = advance(u, u_n, u_nm1, f_a, Cx2, Cy2, dt2)
!ec

=== Efficiency ===

In this example, the C and Fortran code runs at the same speed, and there
are no significant differences in the efficiency of the wrapper code.
The overhead implied by the wrapper code is negligible as long as
there is little numerical work in the `advance` function, or in other
words, that we work with small meshes.

======= Migrating loops to C via f2py =======

idx{`wave2D_u0_loop_c_f2py_signature.f`}

An alternative to using Cython for interfacing C code is to apply
`f2py`. The C code is the same, just the details of specifying how
it is to be called from Python differ. The `f2py` tool requires
the call specification to be a Fortran 90 module defined in a `.pyf`
file. This file was automatically generated when we interfaced a
Fortran subroutine. With a C function we need to write this module
ourselves, or we can use a trick and let `f2py` generate it for us.
The trick consists in writing the signature of the C function with
Fortran syntax and place it in a Fortran file, here
`wave2D_u0_loop_c_f2py_signature.f`:

@@@CODE src-softeng2/wave2D_u0_loop_c_f2py_signature.f
Note that we need a special `f2py` instruction, through a `Cf2py`
comment line, to specify that all the function arguments are
C variables. We also need to tell that the function is actually
in C: `intent(c) advance`.

Since `f2py` is just concerned with the function signature and not the
complete contents of the function body, it can easily generate the
Fortran 90 module specification based solely on the signature above:

!bc sys
Terminal> f2py -m wave2D_u0_loop_c_f2py \
          -h wave2D_u0_loop_c_f2py.pyf --overwrite-signature \
          wave2D_u0_loop_c_f2py_signature.f
!ec
The compile and build step is as for the Fortran code, except that we
list C files instead of Fortran files:

!bc sys
Terminal> f2py -c wave2D_u0_loop_c_f2py.pyf \
          --build-dir tmp_build_c \
          -DF2PY_REPORT_ON_ARRAY_COPY=1 wave2D_u0_loop_c.c
!ec
As when interfacing Fortran code with `f2py`, we need to print out
the doc string to see the exact call syntax from the Python side.
This doc string is identical for the C and Fortran versions of
`advance`.

# No worries with transposed storage, copy of arrays can only take
# place if the type don't match

#===== Migrating loops to C via Instant =====


===== Migrating loops to C++ via f2py =====

C++ is a much more versatile language than C or Fortran and has over
the last two decades become very popular for numerical computing.
Many will therefore prefer to migrate compute-intensive Python code
to C++. This is, in principle, easy: just write the desired C++ code
and use some tool for interfacing it from Python. A tool like
"SWIG": "http://swig.org/" can interpret the C++ code and generate
interfaces for a wide range of
languages, including Python, Perl, Ruby, and Java.
However, SWIG is a comprehensive tool with a correspondingly
steep learning curve. Alternative tools, such as
"Boost Python": "http://www.boost.org/doc/libs/1_51_0/libs/python/doc/index.html", "SIP": "http://riverbankcomputing.co.uk/software/sip/intro",
and "Shiboken": "http://qt-project.org/wiki/Category:LanguageBindings::PySide::Shiboken"
are similarly comprehensive. Simpler tools include
"PyBindGen": "http://code.google.com/p/pybindgen/".

A technically much easier way of interfacing C++ code is to drop the
possibility to use C++ classes directly from Python, but instead
make a C interface to the C++ code. The C interface can be handled
by `f2py` as shown in the example with pure C code. Such a solution
means that classes in Python and C++ cannot be mixed and that only
primitive data types like numbers, strings, and arrays can be
transferred between Python and C++. Actually, this is often a very
good solution because it forces the C++ code to work on array data,
which usually gives faster code than if fancy data structures with
classes are used. The arrays coming from Python, and looking like
plain C/C++ arrays, can be efficiently wrapped in more user-friendly
C++ array classes in the C++ code, if desired.


#__Remaining.__
#Use some array class. Key issue: `extern "C"` declaration of C++
#function in the C file with the interface we want to wrap.


======= Exercises =======

===== Exercise: Explore computational efficiency of numpy.sum versus built-in sum =====
label{softeng2:exer:sum}
file=sumn

Using the task of computing the sum of the first `n` integers, we want to
compare the efficiency of `numpy.sum` versus Python's built-in function
`sum`. Use IPython's `%timeit` functionality to time these two functions
applied to three different arguments: `range(n)`, `xrange(n)`, and
`arange(n)`.

!bsol
Here are experiments in IPython:

!bc ipy
In [1]: a = np.arange(n)

In [2]: %timeit sum(range(n))
10 loops, best of 3: 25 ms per loop

In [3]: %timeit sum(xrange(n))
100 loops, best of 3: 9.91 ms per loop

In [4]: %timeit np.sum(range(n))
10 loops, best of 3: 73.7 ms per loop

In [5]: %timeit np.sum(xrange(n))
10 loops, best of 3: 119 ms per loop

In [6]: %timeit np.sum(a)
1000 loops, best of 3: 630 us per loop

In [7]: %timeit sum(a)
10 loops, best of 3: 95.5 ms per loop
!ec
We observe that `numpy.sum` applied to a `numpy` array is by far the
fastest method. We also see that the plain `sum` function is slow
when applied to arrays, but faster than `numpy.sum` when applied to
the `range` list or the `xrange` sequence. There is almost a factor
of 200 between the best and worst method!
!esol

===== Exercise: Make an improved `numpy.savez` function =====
label{softeng2:exer:savez}
file=Savez

The `numpy.savez` function can save multiple arrays to a zip archive.
Unfortunately, if we want to use `savez` in time-dependent problems
and call it multiple times (once per time level), each call leads
to a separate zip archive. It is more convenient to have all
arrays in one archive, which can be read by `numpy.load`.
Section ref{softeng2:wave1D:filestorage} provides a recipe for
merging all the individual zip archives into one archive.
An alternative is to write a new `savez` function that allows
multiple calls and storage into the same archive prior to a final
`close` method to close the archive and make it ready for reading.
Implement such an improved `savez` function as a class `Savez`.

The class should pass the following unit test:

!bc pycod
def test_Savez():
    import tempfile, os
    tmp = 'tmp_testarchive'
    database = Savez(tmp)
    for i in range(4):
        array = np.linspace(0, 5+i, 3)
        kwargs = {'myarray_%02d' % i: array}
        database.savez(**kwargs)
    database.close()

    database = np.load(tmp+'.npz')

    expected = {
        'myarray_00': np.array([ 0. ,  2.5,  5. ]),
        'myarray_01': np.array([ 0.,  3.,  6.])
        'myarray_02': np.array([ 0. ,  3.5,  7. ]),
        'myarray_03': np.array([ 0.,  4.,  8.]),
        }
    for name in database:
        computed = database[name]
        diff = np.abs(expected[name] - computed).max()
        assert diff < 1E-13
    database.close
    os.remove(tmp+'.npz')
!ec

!bhint
Study the "source code": "https://github.com/numpy/numpy/blob/master/numpy/lib/npyio.py" for function `savez` (or more precisely, function `_savez`).
!ehint

!bsol
Here is the code:

@@@CODE exer-softeng2/Savez.py

# Most of the code is taken from http://stackoverflow.com/questions/22712292/how-to-use-numpy-savez-in-a-loop-for-save-more-than-one-array
!esol

===== Exercise: Visualize the impact of the Courant number =====
label{softeng2:exer:pulse1D:C}
file=pulse1D_Courant

Use the `pulse` function in the `wave1D_dn_vc.py` to simulate a pulse
through two media with different wave velocities. The aim is to
visualize the impact of the Courant number $C$ on the quality of the
solution.  Set `slowness_factor=4` and `Nx=100`.

Simulate for $C=1, 0.9, 0.75$ and make an animation comparing the
three curves (use the `animate_archives.py` program to combine the
curves and make animations on the screen and video files).  Perform
the investigations for different types of initial profiles: a Gaussian
pulse, a ``cosine hat'' pulse, half a ``cosine hat'' pulse, and a plug
pulse.

!bsol
We make a little Python script for running one ``pulse'' simulation:

@@@CODE exer-softeng2/pulse1D_Courant/pulse.py
Then we can make another (Bash) script running through the different types
of simulations and also making video files:

@@@CODE exer-softeng2/pulse1D_Courant/pulse.sh
Note that we make separate directories for the different type initial
profiles.

!esol

===== Exercise: Visualize the impact of the resolution =====
label{softeng2:exer:pulse1D:Nx}
file=pulse1D_Nx

We solve the same set of problems as in Exercise ref{softeng2:exer:pulse1D:C},
except that we now fix $C=1$ and instead study the impact of
$\Delta t$ and $\Delta x$ by varying the `Nx` parameter: 20, 40, 160.
Make animations comparing three such curves.
